def get_jiwer_result(gt: str, hyp: str) -> dict:
    # Handle None or empty inputs
    if gt is None or hyp is None:
        return {
            "wer": 200,
            "substitutions": 0,
            "deletions": 0,
            "insertions": 0,
            "references": 0,
            "hypothesis": 0,
            "alignment": []
        }
    
    # Convert to string and strip whitespace
    gt = str(gt).strip() if gt is not None else ""
    hyp = str(hyp).strip() if hyp is not None else ""
    
    if gt == '' or hyp == '':
        return {
            "wer": 200,
            "substitutions": 0,
            "deletions": 0,
            "insertions": 0,
            "references": 0,
            "hypothesis": 0,
            "alignment": []
        }

    ref_tokens = normalize_string(gt)
    hyp_tokens = normalize_string(hyp)
    
    # Check if normalization resulted in empty tokens
    if not ref_tokens:
        # Empty reference after normalization
        if not hyp_tokens:
            # Both are empty
            return {
                "wer": 0,
                "substitutions": 0,
                "deletions": 0,
                "insertions": 0,
                "references": 0,
                "hypothesis": 0,
                "alignment": []
            }
        else:
            # Only reference is empty after normalization
            return {
                "wer": 100,  # WER is 100% when reference is empty but hypothesis has content
                "substitutions": 0,
                "deletions": 0,
                "insertions": len(hyp_tokens),
                "references": 0,
                "hypothesis": len(hyp_tokens),
                "alignment": []
            }
    
    ref_str = " ".join(ref_tokens)
    hyp_str = " ".join(hyp_tokens)

    try:
        measures = compute_measures(ref_str, hyp_str)
        alignment = process_words(ref_str, hyp_str)
    except Exception as e:
        # Handle jiwer errors
        print(f"Jiwer error: {e} for gt='{gt}', hyp='{hyp}'")
        return {
            "wer": 100,
            "substitutions": 0,
            "deletions": 0,
            "insertions": 0,
            "references": len(ref_tokens),
            "hypothesis": len(hyp_tokens),
            "alignment": []
        }

    aligned_output = []
    for group in alignment.alignments:
        for chunk in group:
            try:
                op = chunk.type
                ref_segment = ref_tokens[chunk.ref_start_idx:chunk.ref_end_idx]
                hyp_segment = hyp_tokens[chunk.hyp_start_idx:chunk.hyp_end_idx]

                if op == 'equal':
                    for rw, hw in zip(ref_segment, hyp_segment):
                        aligned_output.append(f"CORRECT | {rw} | {hw}")
                elif op == 'substitute':
                    for rw, hw in zip(ref_segment, hyp_segment):
                        aligned_output.append(f"SUBSTITUTION | {rw} | {hw}")
                elif op == 'insert':
                    for hw in hyp_segment:
                        aligned_output.append(f"INSERTION |  | {hw}")
                elif op == 'delete':
                    for rw in ref_segment:
                        aligned_output.append(f"DELETION | {rw} | ")
            except Exception:
                continue

    return {
        "wer": 100 * min(1.0, round(measures['wer'], 2)),
        "substitutions": measures['substitutions'],
        "deletions": measures['deletions'],
        "insertions": measures['insertions'],
        "references": len(ref_tokens),
        "hypothesis": len(hyp_tokens),
        "alignment": aligned_output
    }