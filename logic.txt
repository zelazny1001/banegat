

# === constants.py ===

# constants.py

from __future__ import annotations

USE_HALLUCINATION_FLAGS: bool = False
CODE_IS_BEING_TESTED: bool = True
INCLUDE_CONDITIONS = False

ROOT_DIR: str = "j:/projects/sheet-logic/asr-april-2025-data/"
SPREADSHEET_PREFIX: str = "ASR"
WORKSHEET_PREFIX: str = "ASR"
METRICS_CONDITION_TEMPLATE = "metrics-condition-template.xlsx"
DO_MONTHLY_CONSOLIDATION: bool = True
CALL_LEVEL_GRANULARITY: bool = True # False means sample level granularity
AVERAGING_PERIOD = "weekly" # or "monthly"

SESSION_ID_COL_NAME: str = "session_id"
RAW_TRANSCRIPT_COL_NAME: str = "raw_transcript"
GROUND_TRUTH_COL_NAME: str = "Ground Truth Transcript"
HALLUCINATION_COL_NAME: str = "Hallucination"

INPUT_DATA_WORKSHEET_NAME: str = "input-data"

METRICS_WORKSHEET_NAME: str = "metrics"
METADATA_COL_NAME: str = "metadata"
SECTION_COL_NAME: str = "section"
ENTIRE_COL_NAME: str = "entire"
GT_SECTION_TEXT_COL_NAME: str = "gt section"
MODEL_SECTION_TEXT_COL_NAME: str = "model text"
WER_COL_NAME: str = "WER"
HALLUCINATION_COUNT_COL_NAME: str = "Hallucination"
GT_TOKS_COL_NAME: str = "GT Toks"
HALLUCINATION_PERCENT_COL_NAME: str = "Hallucination %"

NUMBER_OF_SECTIONS: int = 5
WER_POST_ENDPOINT: str = "https://wer_host:3281/word_error_rate"
WER_ALGORITHM = "nltk"

WEEKLY_SUMMARY_WORKSHEET_NAME: str = "weekly-summary"
MONTHLY_SUMMARY_WORKSHEET_NAME: str = "monthly-summary"

AVERAGE_WER_COL_NAME: str = "AVG_WER"
SESSION_COUNT_COL_NAME: str = "num sessions"
SUMMARY_HALLUCINATION_COUNT_COL_NAME: str = "Hallucination Count"
HALLUCINATION_AVG_COL_NAME: str = "Hallucination Avg"
AVG_HALLUCINATION_PERCENT_COL_NAME: str = "Avg Hallucination %"

CALL_LEVEL_BKGND_COLOR: str = "00FFFF"
SAMPLE_LEVEL_BKGND_COLOR: str = "FFFFFF"
SOURCE_COL_WIDTHS = {"A": 69, "B": 35, "C": 35, "D": 12}
METRICS_HEADER_COL_WIDTHS = {"A": 27, "B": 65, "C": 9, "D": 63, "E": 63, "F": 8, "G": 12, "H": 10, "I": 15}
SUMMARY_COL_WIDTHS = {"A": 30, "B": 13, "C": 16, "D": 22}

# Agent / Customer interaction support

VTYPE_COL_NAME: str = "vtype"
AGENT_VALUE: str = "Agent"
CUSTOMER_VALUE: str = "Customer"


# === interleaved_orchestrator.py ===

from __future__ import annotations
from typing import Dict, List, Tuple
from pathlib import Path
from openpyxl import load_workbook, Workbook
from openpyxl.worksheet.worksheet import Worksheet
from constants import (
    INPUT_DATA_WORKSHEET_NAME,
    METRICS_WORKSHEET_NAME,
    WEEKLY_SUMMARY_WORKSHEET_NAME,
    MONTHLY_SUMMARY_WORKSHEET_NAME,
    METADATA_COL_NAME,
    SESSION_ID_COL_NAME,
    RAW_TRANSCRIPT_COL_NAME,
    GROUND_TRUTH_COL_NAME,
    VTYPE_COL_NAME,
)
from interleaved_processing import separate_interleaved_sessions_by_vtype, process_interleaved_session
from interleaved_summary import generate_interleaved_weekly_summary

def _load_input_ws(path: str) -> Worksheet:
    wb = load_workbook(path, read_only=True)
    return wb[INPUT_DATA_WORKSHEET_NAME] if INPUT_DATA_WORKSHEET_NAME in wb.sheetnames else wb.active

def _build_metrics_wb() -> Workbook:
    wb = Workbook()
    ws = wb.active
    ws.title = METRICS_WORKSHEET_NAME
    ws.append([METADATA_COL_NAME, SESSION_ID_COL_NAME, VTYPE_COL_NAME, "section", "gt_section_text", "model_section_text", "WER", "Hallucination Count", "GT Tokens", "Hallucination %"])
    return wb

def _header_map(ws: Worksheet) -> Dict[str, int]:
    header = [c.value for c in next(ws.iter_rows(min_row=1, max_row=1))]
    return {name: idx for idx, name in enumerate(header)}

def _metadata_to_sessions(ws: Worksheet) -> Dict[str, List[str]]:
    hm = _header_map(ws)
    mi = hm[METADATA_COL_NAME]
    si = hm[SESSION_ID_COL_NAME]
    seen: Dict[str, set] = {}
    for row in ws.iter_rows(min_row=2, values_only=True):
        meta = str(row[mi]).strip() if row[mi] is not None else ""
        sid = str(row[si]).strip() if row[si] is not None else ""
        if not meta or not sid:
            continue
        seen.setdefault(meta, set()).add(sid)
    return {k: sorted(list(v)) for k, v in seen.items()}

def build_interleaved_metrics_workbook_from_input(input_path: str) -> str:
    src_ws = _load_input_ws(input_path)
    metrics_wb = _build_metrics_wb()
    metrics_ws = metrics_wb[METRICS_WORKSHEET_NAME]
    meta_sessions = _metadata_to_sessions(src_ws)
    for metadata_value, session_ids in meta_sessions.items():
        for session_id in session_ids:
            blocks = separate_interleaved_sessions_by_vtype(src_ws, session_id)
            if not blocks:
                continue
            process_interleaved_session(src_ws, metrics_ws, metadata_value, session_id, blocks)
    weekly_ws = metrics_wb.create_sheet(WEEKLY_SUMMARY_WORKSHEET_NAME)
    generate_interleaved_weekly_summary(metrics_ws, weekly_ws)
    out = str(Path(input_path).with_name(f"{Path(input_path).stem}_metrics.xlsx"))
    metrics_wb.save(out)
    return out

def write_interleaved_monthly_summary(workbook: Workbook) -> None:
    metrics_ws = workbook[METRICS_WORKSHEET_NAME]
    summary_ws = workbook.create_sheet(MONTHLY_SUMMARY_WORKSHEET_NAME)
    generate_interleaved_weekly_summary(metrics_ws, summary_ws)


# === main.py ===

from __future__ import annotations
from openpyxl import load_workbook
from constants import ROOT_DIR, SPREADSHEET_PREFIX, DO_MONTHLY_CONSOLIDATION, INCLUDE_CONDITIONS, INPUT_DATA_WORKSHEET_NAME, VTYPE_COL_NAME
from monthly_aggregation_and_summary import list_input_spreadsheets, build_metrics_workbook_from_input, create_monthly_workbook, qualifies_for_processing
from metrics_conditions import append_metrics_conditions_worksheet
from interleaved_orchestrator import build_interleaved_metrics_workbook_from_input, write_interleaved_monthly_summary

def has_vtype_column(input_path: str, worksheet_name: str) -> bool:
    wb = load_workbook(input_path, read_only=True)
    try:
        ws = wb[worksheet_name] if worksheet_name in wb.sheetnames else wb[INPUT_DATA_WORKSHEET_NAME]
    except KeyError:
        ws = wb.active
    header = [c.value for c in next(ws.iter_rows(min_row=1, max_row=1))]
    return VTYPE_COL_NAME in header

def main() -> None:
    input_files = list_input_spreadsheets(ROOT_DIR)
    metrics_files: list[str] = []
    for index, input_path in enumerate(input_files, start=1):
        ok, ws_name = qualifies_for_processing(input_path)
        if not ok:
            print(f"{index}/{len(input_files)} Skipping {input_path}: no worksheet starting with {SPREADSHEET_PREFIX}")
            continue
        if has_vtype_column(input_path, ws_name):
            output_path = build_interleaved_metrics_workbook_from_input(input_path)
        else:
            output_path = build_metrics_workbook_from_input(input_path)
        if output_path:
            metrics_files.append(output_path)
            print(f"{index}/{len(input_files)} Saved metrics and summaries to {output_path}")
    if DO_MONTHLY_CONSOLIDATION and metrics_files:
        monthly_path, monthly_workbook = create_monthly_workbook(ROOT_DIR, metrics_files, SPREADSHEET_PREFIX)
        if has_vtype_column(input_files[0], qualifies_for_processing(input_files[0])[1]):
            write_interleaved_monthly_summary(monthly_workbook)
        if INCLUDE_CONDITIONS:
            append_metrics_conditions_worksheet(monthly_workbook)
        monthly_workbook.save(monthly_path)
        print(f"Saved monthly consolidated metrics to {monthly_path}")

if __name__ == "__main__":
    main()
