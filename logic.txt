# threshold_analyzer.py

from openpyxl import load_workbook
from openpyxl.styles import Font
from openpyxl.utils.dataframe import dataframe_to_rows
import pandas as pd
from typing import List, Dict, Tuple
from dataclasses import dataclass

@dataclass
class AnalysisConfig:
  workbook_path: str
  target_worksheet: str
  analysis_worksheet: str
  metrics_worksheet: str
  metrics2_worksheet: str
  thresholds: List[float]
  columns_of_interest: List[str]
  token_buckets: List[Tuple[str, int, int]]

class UtteranceData:
  def __init__(self, row_data: Dict[str, any]):
    self.utterance = row_data.get("Utterance", "")
    self.expected_intent = row_data.get("Expected Intent", "")
    self.processed_intent = row_data.get("Processed Intent", "")
    self.probability = row_data.get("Probability", 0.0)
    self.original_classification = row_data.get("TN/TP/FN/FP", "")

  def compute_token_count(self) -> int:
    return len(self.utterance.split())

  def get_prediction_at_threshold(self, threshold: float) -> str:
    if self.probability >= threshold:
      return self.processed_intent
    return "OTHER"

  def compute_classification(self, predicted_intent: str) -> str:
    if self.expected_intent == "CDP" and predicted_intent == "CDP":
      return "TP"
    elif self.expected_intent == "CDP" and predicted_intent == "OTHER":
      return "FN"
    elif self.expected_intent == "OTHER" and predicted_intent == "CDP":
      return "FP"
    elif self.expected_intent == "OTHER" and predicted_intent == "OTHER":
      return "TN"
    elif self.expected_intent == predicted_intent:
      return "TP"
    else:
      return "TN"

  def get_token_bucket(self, buckets: List[Tuple[str, int, int]]) -> str:
    token_count = self.compute_token_count()
    for bucket_name, min_tokens, max_tokens in buckets:
      if max_tokens == -1:
        if token_count >= min_tokens:
          return bucket_name
      elif min_tokens <= token_count <= max_tokens:
        return bucket_name
    return "unknown"

class BinaryClassificationMetrics:
  def __init__(self):
    self.tp = 0
    self.fp = 0
    self.fn = 0
    self.tn = 0

  def add_prediction(self, expected: str, predicted: str):
    if expected == "CDP" and predicted == "CDP":
      self.tp += 1
    elif expected == "CDP" and predicted == "OTHER":
      self.fn += 1
    elif expected == "OTHER" and predicted == "CDP":
      self.fp += 1
    elif expected == "OTHER" and predicted == "OTHER":
      self.tn += 1

  def compute_precision(self) -> float:
    if self.tp + self.fp == 0:
      return 0.0
    return self.tp / (self.tp + self.fp)

  def compute_recall(self) -> float:
    if self.tp + self.fn == 0:
      return 0.0
    return self.tp / (self.tp + self.fn)

  def compute_f1(self) -> float:
    precision = self.compute_precision()
    recall = self.compute_recall()
    if precision + recall == 0:
      return 0.0
    return 2 * (precision * recall) / (precision + recall)

  def compute_f0_5(self) -> float:
    precision = self.compute_precision()
    recall = self.compute_recall()
    if precision + recall == 0:
      return 0.0
    beta = 0.5
    return (1 + beta ** 2) * (precision * recall) / ((beta ** 2 * precision) + recall)

  def get_count(self) -> int:
    return self.tp + self.fp + self.fn + self.tn

class ThresholdAnalyzer:
  def __init__(self, config: AnalysisConfig):
    self.config = config
    self.utterance_data_list: List[UtteranceData] = []
    self.analysis_df: pd.DataFrame = None
    self.metrics_df: pd.DataFrame = None

  def load_data(self):
    df = pd.read_excel(self.config.workbook_path, sheet_name=self.config.target_worksheet)
    for _, row in df.iterrows():
      utterance_data = UtteranceData(row.to_dict())
      self.utterance_data_list.append(utterance_data)

  def analyze(self):
    records = []

    for utterance_data in self.utterance_data_list:
      record = {
        "Utterance": utterance_data.utterance,
        "Expected Intent": utterance_data.expected_intent,
        "Processed Intent": utterance_data.processed_intent,
        "Probability": utterance_data.probability,
        "TN/TP/FN/FP": utterance_data.original_classification,
        "token count": utterance_data.compute_token_count()
      }

      for threshold in self.config.thresholds:
        prediction_key = f"prediction at {threshold}"
        classification_key = f"TN/TP/FN/FP at {threshold}"

        prediction = utterance_data.get_prediction_at_threshold(threshold)
        record[prediction_key] = prediction
        record[classification_key] = utterance_data.compute_classification(prediction)

      records.append(record)

    self.analysis_df = pd.DataFrame(records)

  def compute_metrics(self):
    metrics_records = []

    for threshold in self.config.thresholds:
      overall_metrics = BinaryClassificationMetrics()

      for utterance_data in self.utterance_data_list:
        expected = utterance_data.expected_intent
        predicted = utterance_data.get_prediction_at_threshold(threshold)

        if expected in ["CDP", "OTHER"] and predicted in ["CDP", "OTHER"]:
          overall_metrics.add_prediction(expected, predicted)

      metrics_records.append({
        "Section": "Overall",
        "Token Bucket": "All",
        "Threshold": threshold,
        "Precision": overall_metrics.compute_precision(),
        "Recall": overall_metrics.compute_recall(),
        "F1": overall_metrics.compute_f1(),
        "F0.5": overall_metrics.compute_f0_5(),
        "TP": overall_metrics.tp,
        "FP": overall_metrics.fp,
        "FN": overall_metrics.fn,
        "TN": overall_metrics.tn,
        "Count": overall_metrics.get_count()
      })

    for bucket_name, min_tokens, max_tokens in self.config.token_buckets:
      for threshold in self.config.thresholds:
        bucket_metrics = BinaryClassificationMetrics()

        for utterance_data in self.utterance_data_list:
          if utterance_data.get_token_bucket(self.config.token_buckets) == bucket_name:
            expected = utterance_data.expected_intent
            predicted = utterance_data.get_prediction_at_threshold(threshold)

            if expected in ["CDP", "OTHER"] and predicted in ["CDP", "OTHER"]:
              bucket_metrics.add_prediction(expected, predicted)

        metrics_records.append({
          "Section": "By Token Length",
          "Token Bucket": bucket_name,
          "Threshold": threshold,
          "Precision": bucket_metrics.compute_precision(),
          "Recall": bucket_metrics.compute_recall(),
          "F1": bucket_metrics.compute_f1(),
          "F0.5": bucket_metrics.compute_f0_5(),
          "TP": bucket_metrics.tp,
          "FP": bucket_metrics.fp,
          "FN": bucket_metrics.fn,
          "TN": bucket_metrics.tn,
          "Count": bucket_metrics.get_count()
        })

    self.metrics_df = pd.DataFrame(metrics_records)

  def write_results(self):
    from openpyxl.chart import LineChart, Reference

    workbook = load_workbook(self.config.workbook_path)

    if self.config.analysis_worksheet in workbook.sheetnames:
      del workbook[self.config.analysis_worksheet]

    analysis_ws = workbook.create_sheet(self.config.analysis_worksheet)

    for row_idx, row in enumerate(dataframe_to_rows(self.analysis_df, index=False, header=True), start=1):
      for col_idx, value in enumerate(row, start=1):
        cell = analysis_ws.cell(row=row_idx, column=col_idx, value=value)
        cell.font = Font(name="Aptos", size=9)

        if row_idx == 1:
          cell.font = Font(name="Aptos", size=9, bold=True)

    analysis_ws.freeze_panes = "A2"
    analysis_ws.auto_filter.ref = analysis_ws.dimensions

    if self.config.metrics_worksheet in workbook.sheetnames:
      del workbook[self.config.metrics_worksheet]

    metrics_ws = workbook.create_sheet(self.config.metrics_worksheet)

    for row_idx, row in enumerate(dataframe_to_rows(self.metrics_df, index=False, header=True), start=1):
      for col_idx, value in enumerate(row, start=1):
        cell = metrics_ws.cell(row=row_idx, column=col_idx, value=value)
        cell.font = Font(name="Aptos", size=9)

        if row_idx == 1:
          cell.font = Font(name="Aptos", size=9, bold=True)

    metrics_ws.freeze_panes = "A2"
    metrics_ws.auto_filter.ref = metrics_ws.dimensions

    if self.config.metrics2_worksheet in workbook.sheetnames:
      del workbook[self.config.metrics2_worksheet]

    metrics2_ws = workbook.create_sheet(self.config.metrics2_worksheet)
    self._create_metrics2_worksheet(metrics2_ws)

    workbook.save(self.config.workbook_path)

  def _create_metrics2_worksheet(self, worksheet):
    by_token_data = self.metrics_df[self.metrics_df['Section'] == 'By Token Length']
    overall_data = self.metrics_df[self.metrics_df['Section'] == 'Overall']

    row = 1

    for threshold in self.config.thresholds:
      worksheet.cell(row=row, column=1, value="Threshold")
      worksheet.cell(row=row, column=2, value=threshold)
      worksheet.cell(row=row, column=1).font = Font(name="Aptos", size=9, bold=True)
      worksheet.cell(row=row, column=2).font = Font(name="Aptos", size=9, bold=True)
      row += 1

      worksheet.cell(row=row, column=1, value="token length")
      worksheet.cell(row=row, column=2, value="TP")
      worksheet.cell(row=row, column=3, value="FP")
      worksheet.cell(row=row, column=4, value="FN")
      worksheet.cell(row=row, column=5, value="Precision")
      worksheet.cell(row=row, column=6, value="Recall")
      worksheet.cell(row=row, column=7, value="F1")
      worksheet.cell(row=row, column=8, value="F0.5")
      for col in range(1, 9):
        worksheet.cell(row=row, column=col).font = Font(name="Aptos", size=9, bold=True)
      row += 1

      overall_row = overall_data[overall_data['Threshold'] == threshold]
      if not overall_row.empty:
        data = overall_row.iloc[0]
        worksheet.cell(row=row, column=1, value="All")
        worksheet.cell(row=row, column=2, value=data['TP'])
        worksheet.cell(row=row, column=3, value=data['FP'])
        worksheet.cell(row=row, column=4, value=data['FN'])
        worksheet.cell(row=row, column=5, value=data['Precision'])
        worksheet.cell(row=row, column=6, value=data['Recall'])
        worksheet.cell(row=row, column=7, value=data['F1'])
        worksheet.cell(row=row, column=8, value=data['F0.5'])
        for col in range(1, 9):
          worksheet.cell(row=row, column=col).font = Font(name="Aptos", size=9)
        row += 1

      for bucket_name, _, _ in self.config.token_buckets:
        bucket_row = by_token_data[
          (by_token_data['Token Bucket'] == bucket_name) &
          (by_token_data['Threshold'] == threshold)
          ]

        display_name = bucket_name.replace("tokens", "tokens")
        if bucket_name == "1-3 tokens":
          display_name = "1 to 3 tokens"
        elif bucket_name == "4-20 tokens":
          display_name = "4 to 20 tokens"
        elif bucket_name == ">20 tokens":
          display_name = "> 20 tokens"

        if not bucket_row.empty:
          data = bucket_row.iloc[0]
          worksheet.cell(row=row, column=1, value=display_name)
          worksheet.cell(row=row, column=2, value=data['TP'])
          worksheet.cell(row=row, column=3, value=data['FP'])
          worksheet.cell(row=row, column=4, value=data['FN'])
          worksheet.cell(row=row, column=5, value=data['Precision'])
          worksheet.cell(row=row, column=6, value=data['Recall'])
          worksheet.cell(row=row, column=7, value=data['F1'])
          worksheet.cell(row=row, column=8, value=data['F0.5'])
          for col in range(1, 9):
            worksheet.cell(row=row, column=col).font = Font(name="Aptos", size=9)
        row += 1

      row += 1

class ThresholdAnalysisOrchestrator:
  def __init__(self, workbook_path: str, target_worksheet: str,
               analysis_worksheet: str, metrics_worksheet: str,
               metrics2_worksheet: str, thresholds: List[float]):
    columns_of_interest = [
      "Utterance", "Expected Intent", "Processed Intent",
      "Probability", "TN/TP/FN/FP"
    ]

    token_buckets = [
      ("1-3 tokens", 1, 3),
      ("4-20 tokens", 4, 20),
      (">20 tokens", 21, -1)
    ]

    self.config = AnalysisConfig(
      workbook_path=workbook_path,
      target_worksheet=target_worksheet,
      analysis_worksheet=analysis_worksheet,
      metrics_worksheet=metrics_worksheet,
      metrics2_worksheet=metrics2_worksheet,
      thresholds=thresholds,
      columns_of_interest=columns_of_interest,
      token_buckets=token_buckets
    )

    self.analyzer = ThresholdAnalyzer(self.config)

  def run(self):
    self.analyzer.load_data()
    self.analyzer.analyze()
    self.analyzer.compute_metrics()
    self.analyzer.write_results()

def main():
  WORKBOOK_PATH = "threshold_data.xlsx"
  TARGET_WORKSHEET = "results"
  ANALYSIS_WORKSHEET = "analysis"
  METRICS_WORKSHEET = "metrics"
  METRICS2_WORKSHEET = "metrics2"
  THRESHOLDS = [0.7, 0.78, 0.85, 0.9]

  orchestrator = ThresholdAnalysisOrchestrator(
    workbook_path=WORKBOOK_PATH,
    target_worksheet=TARGET_WORKSHEET,
    analysis_worksheet=ANALYSIS_WORKSHEET,
    metrics_worksheet=METRICS_WORKSHEET,
    metrics2_worksheet=METRICS2_WORKSHEET,
    thresholds=THRESHOLDS
  )

  orchestrator.run()
  print(f"Analysis complete.")
  print(f"Results written to worksheet: {ANALYSIS_WORKSHEET}")
  print(f"Metrics written to worksheet: {METRICS_WORKSHEET}")
  print(f"Metrics2 written to worksheet: {METRICS2_WORKSHEET}")

if __name__ == "__main__":
  main()