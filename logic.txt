#=== start modification for timestamp - constants.py
TIMESTAMP_COL_NAME: str = "Timestamp"
DURATION_COL_NAME: str = "duration"
TRANSCRIPT_DENSITY_COL_NAME: str = "Toks/Sec."
AVERAGE_TRX_DENSITY_COL_NAME: str = "Avg. Toks/Sec."
#=== end modification for timestamp

#=== start modification for timestamp - constants.py
METRICS_HEADER_COL_WIDTHS = {"A": 27, "B": 65, "C": 9, "D": 63, "E": 63, "F": 8, "G": 12, "H": 10, "I": 15, "J": 12, "K": 12}
SUMMARY_COL_WIDTHS = {"A": 30, "B": 13, "C": 16, "D": 22, "E": 15}
#=== end modification for timestamp

#=== start modification for timestamp - data_models.py
@dataclass
class TranscriptPair:
    transcript: str
    ground_truth: str
    timestamp: Optional[int] = None
    duration: int = 0
#=== end modification for timestamp

#=== start modification for timestamp - data_models.py
@dataclass
class MetricsRow:
    metadata: str
    session_id: str
    section: str
    ground_truth_text: str
    model_text: str
    wer: float
    hallucination_count: int
    ground_truth_tokens: int
    hallucination_percent: Optional[float]
    hallucination_text: str
    is_entire: bool = False
    duration: int = 0
    transcript_density: Optional[float] = None
#=== end modification for timestamp

#=== start modification for timestamp - data_models.py
@dataclass
class SummaryData:
    metadata: str
    average_wer: float
    session_count: int
    average_hallucination_percent: float
    speaker: Optional[str] = None
    average_transcript_density: Optional[float] = None
#=== end modification for timestamp

  # === start modification for timestamp - metrics_calculator.py
  def calculate_metrics_for_section(
      self,
      metadata: str,
      session_id: str,
      section_label: str,
      pairs: list[TranscriptPair],
      hallucination_counts: list[int],
      hallucination_texts: list[str],
      is_entire: bool = False
  ) -> MetricsRow:
    if not pairs:
      return MetricsRow(
        metadata=metadata,
        session_id=session_id,
        section=section_label,
        ground_truth_text="",
        model_text="",
        wer=float("nan"),
        hallucination_count=0,
        ground_truth_tokens=0,
        hallucination_percent=None,
        hallucination_text="",
        is_entire=is_entire,
        duration=0,
        transcript_density=None
      )

    gt_text, model_text, wer, gt_tokens = self.wer_calculator.calculate_for_pairs(pairs)
    hallucination_total = sum(hallucination_counts)
    hallucination_percent = (100 * hallucination_total / gt_tokens) if gt_tokens else None
    hallucination_text = " ".join(hallucination_texts)

    total_duration = sum(p.duration for p in pairs)
    model_tokens = len(model_text.split()) if model_text else 0
    transcript_density = (1000 * model_tokens) /total_duration if total_duration > 0 else None

    return MetricsRow(
      metadata=metadata,
      session_id=session_id,
      section=section_label,
      ground_truth_text=gt_text,
      model_text=model_text,
      wer=wer,
      hallucination_count=hallucination_total,
      ground_truth_tokens=gt_tokens,
      hallucination_percent=hallucination_percent,
      hallucination_text=hallucination_text,
      is_entire=is_entire,
      duration=total_duration,
      transcript_density=transcript_density
    )
  # === end modification for timestamp
  
#=== start modification for timestamp - styling.py
def style_metrics_columns(worksheet: Worksheet) -> None:
    for col_index, width in {1: 27, 2: 65, 3: 9, 4: 63, 5: 63, 6: 9, 7: 12, 8: 10, 9: 15, 10: 12, 11: 12}.items():
        worksheet.column_dimensions[get_column_letter(col_index)].width = width
    worksheet.auto_filter.ref = f"A1:K{worksheet.max_row}"
#=== end modification for timestamp

  # === start modification for timestamp - summary_calculator.py
  def calculate_overall_summary(self, metrics_worksheet: Worksheet) -> list[SummaryData]:
    self.metrics_worksheet = metrics_worksheet
    header_map = {c.value: idx for idx, c in enumerate(metrics_worksheet[1], start=1)}
    rows = list(metrics_worksheet.iter_rows(min_row=2, values_only=True))

    wer_index = header_map[WER_COL_NAME] - 1
    hallucination_percent_index = header_map[HALLUCINATION_PERCENT_COL_NAME] - 1
    section_index = header_map[SECTION_COL_NAME] - 1
    metadata_index = header_map[METADATA_COL_NAME] - 1

    has_speakers = self.has_speaker_sections(metrics_worksheet)

    if has_speakers:
      return self._calculate_speaker_summary(
        rows, wer_index, hallucination_percent_index, section_index, metadata_index
      )
    else:
      return self._calculate_non_speaker_summary(
        rows, wer_index, hallucination_percent_index, section_index, metadata_index
      )
  # === end modification for timestamp

  # === start modification for timestamp - summary_calculator.py
  def _calculate_speaker_summary(
      self,
      rows: list,
      wer_index: int,
      hallucination_percent_index: int,
      section_index: int,
      metadata_index: int
  ) -> list[SummaryData]:
    summaries: list[SummaryData] = []

    density_index = None
    for idx, cell in enumerate(self.metrics_worksheet[1]):
      if cell.value == TRANSCRIPT_DENSITY_COL_NAME:
        density_index = idx
        break

    for speaker in [CUSTOMER_VALUE, AGENT_VALUE]:
      if CALL_LEVEL_GRANULARITY:
        wer_values = [
          row[wer_index] for row in rows
          if row[section_index] == speaker and isinstance(row[wer_index], (int, float))
        ]
        hallucination_values = [
          row[hallucination_percent_index] for row in rows
          if row[section_index] == speaker and isinstance(row[hallucination_percent_index], (int, float))
        ]
        density_values = [
          row[density_index] for row in rows
          if density_index is not None and row[section_index] == speaker
             and isinstance(row[density_index], (int, float))
        ] if density_index is not None else []
      else:
        wer_values = [
          row[wer_index] for row in rows
          if isinstance(row[section_index], str) and row[section_index].startswith(speaker)
             and row[section_index] != speaker and isinstance(row[wer_index], (int, float))
        ]
        hallucination_values = [
          row[hallucination_percent_index] for row in rows
          if isinstance(row[section_index], str) and row[section_index].startswith(speaker)
             and row[section_index] != speaker and isinstance(row[hallucination_percent_index], (int, float))
        ]
        density_values = [
          row[density_index] for row in rows
          if density_index is not None
             and isinstance(row[section_index], str)
             and row[section_index].startswith(speaker)
             and row[section_index] != speaker
             and isinstance(row[density_index], (int, float))
        ] if density_index is not None else []

      average_wer = sum(wer_values) / len(wer_values) if wer_values else 0.0
      average_hallucination = sum(hallucination_values) / len(hallucination_values) if hallucination_values else 0.0
      average_density = sum(density_values) / len(density_values) if density_values else None
      session_count = sum(1 for row in rows if row[section_index] == speaker)
      normalized_meta = self.normalizer.normalize(rows, metadata_index, SPREADSHEET_PREFIX)

      summaries.append(SummaryData(
        metadata=normalized_meta,
        average_wer=average_wer,
        session_count=session_count,
        average_hallucination_percent=average_hallucination,
        speaker=speaker,
        average_transcript_density=average_density
      ))

    return summaries
  # === end modification for timestamp
  
  #=== start modification for timestamp - summary_calculator.py
  def _calculate_non_speaker_summary(
      self,
      rows: list,
      wer_index: int,
      hallucination_percent_index: int,
      section_index: int,
      metadata_index: int
  ) -> list[SummaryData]:
      density_index = None
      for idx, cell in enumerate(self.metrics_worksheet[1]):
          if cell.value == TRANSCRIPT_DENSITY_COL_NAME:
              density_index = idx
              break

      if CALL_LEVEL_GRANULARITY:
          wer_values = [
              row[wer_index] for row in rows
              if row[section_index] == ENTIRE_COL_NAME and isinstance(row[wer_index], (int, float))
          ]
          hallucination_values = [
              row[hallucination_percent_index] for row in rows
              if row[section_index] == ENTIRE_COL_NAME and isinstance(row[hallucination_percent_index], (int, float))
          ]
          density_values = [
              row[density_index] for row in rows
              if density_index is not None and row[section_index] == ENTIRE_COL_NAME
              and isinstance(row[density_index], (int, float))
          ] if density_index is not None else []
      else:
          wer_values = [
              row[wer_index] for row in rows
              if row[section_index] != ENTIRE_COL_NAME and isinstance(row[wer_index], (int, float))
          ]
          hallucination_values = [
              row[hallucination_percent_index] for row in rows
              if row[section_index] != ENTIRE_COL_NAME and isinstance(row[hallucination_percent_index], (int, float))
          ]
          density_values = [
              row[density_index] for row in rows
              if density_index is not None and row[section_index] != ENTIRE_COL_NAME
              and isinstance(row[density_index], (int, float))
          ] if density_index is not None else []

      average_wer = sum(wer_values) / len(wer_values) if wer_values else 0.0
      average_hallucination = sum(hallucination_values) / len(hallucination_values) if hallucination_values else 0.0
      average_density = sum(density_values) / len(density_values) if density_values else None
      normalized_meta = self.normalizer.normalize(rows, metadata_index, SPREADSHEET_PREFIX)
      session_count = sum(1 for row in rows if row[section_index] == ENTIRE_COL_NAME)

      return [SummaryData(
          metadata=normalized_meta,
          average_wer=average_wer,
          session_count=session_count,
          average_hallucination_percent=average_hallucination,
          average_transcript_density=average_density
      )]
  #=== end modification for timestamp
  
  # === start modification for timestamp - worksheet_reader.py
  def read_sessions(self) -> dict[str, SessionData]:
    session_id_index = self.header_map[SESSION_ID_COL_NAME] - 1
    raw_transcript_index = self.header_map[RAW_TRANSCRIPT_COL_NAME] - 1
    ground_truth_index = self.header_map[GROUND_TRUTH_COL_NAME] - 1
    timestamp_index = self.header_map.get(TIMESTAMP_COL_NAME, 0) - 1 if TIMESTAMP_COL_NAME in self.header_map else None

    sessions: dict[str, list[TranscriptPair]] = {}
    prev_session_id = None
    prev_timestamp = None

    for row in self.worksheet.iter_rows(min_row=2, values_only=True):
      session_id = str(row[session_id_index] or "").strip()
      if not session_id:
        continue

      timestamp = None
      duration = 0
      if timestamp_index is not None and timestamp_index >= 0 and len(row) > timestamp_index:
        timestamp_value = row[timestamp_index]
        if timestamp_value is not None:
          timestamp = int(timestamp_value)
          if prev_session_id == session_id and prev_timestamp is not None:
            duration = timestamp - prev_timestamp

      pair = TranscriptPair(
        transcript=row[raw_transcript_index],
        ground_truth=row[ground_truth_index],
        timestamp=timestamp,
        duration=duration
      )
      sessions.setdefault(session_id, []).append(pair)

      prev_session_id = session_id
      prev_timestamp = timestamp

    return {
      sid: SessionData(session_id=sid, transcript_pairs=pairs)
      for sid, pairs in sessions.items()
    }
  # === end modification for timestamp

  # === start modification for timestamp - worksheet_reader.py
  def read_speaker_sessions(self) -> dict[str, SpeakerSessionData]:
    session_id_index = self.header_map[SESSION_ID_COL_NAME] - 1
    raw_transcript_index = self.header_map[RAW_TRANSCRIPT_COL_NAME] - 1
    ground_truth_index = self.header_map[GROUND_TRUTH_COL_NAME] - 1
    vtype_index = self.header_map[VTYPE_COL_NAME] - 1
    timestamp_index = self.header_map.get(TIMESTAMP_COL_NAME, 0) - 1 if TIMESTAMP_COL_NAME in self.header_map else None

    sessions: dict[str, SpeakerSessionData] = {}
    prev_session_id = None
    prev_timestamp = None

    for row in self.worksheet.iter_rows(min_row=2, values_only=True):
      session_id = str(row[session_id_index] or "").strip()
      if not session_id:
        continue

      if session_id not in sessions:
        sessions[session_id] = SpeakerSessionData(session_id=session_id)

      timestamp = None
      duration = 0
      if timestamp_index is not None and timestamp_index >= 0 and len(row) > timestamp_index:
        timestamp_value = row[timestamp_index]
        if timestamp_value is not None:
          timestamp = int(timestamp_value)
          if prev_session_id == session_id and prev_timestamp is not None:
            duration = timestamp - prev_timestamp

      vtype = str(row[vtype_index] or "").strip()
      pair = TranscriptPair(
        transcript=row[raw_transcript_index],
        ground_truth=row[ground_truth_index],
        timestamp=timestamp,
        duration=duration
      )

      if vtype == CUSTOMER_VALUE:
        sessions[session_id].customer_pairs.append(pair)
      elif vtype == AGENT_VALUE:
        sessions[session_id].agent_pairs.append(pair)

      prev_session_id = session_id
      prev_timestamp = timestamp

    return sessions
  # === end modification for timestamp

  # === start modification for timestamp - worksheet_writer.py
  def _write_header(self) -> None:
    headers = [
      METADATA_COL_NAME,
      SESSION_ID_COL_NAME,
      SECTION_COL_NAME,
      GT_SECTION_TEXT_COL_NAME,
      MODEL_SECTION_TEXT_COL_NAME,
      WER_COL_NAME,
      HALLUCINATION_COUNT_COL_NAME,
      GT_TOKS_COL_NAME,
      HALLUCINATION_PERCENT_COL_NAME,
      HALLUCINATION_COL_NAME,
      DURATION_COL_NAME,
      TRANSCRIPT_DENSITY_COL_NAME,
    ]

    for col_index, title in enumerate(headers, start=1):
      cell = self.worksheet.cell(1, col_index, title)
      cell.font = Font(name="Aptos", size=9, bold=True)
      cell.alignment = Alignment("left", "center")

    self.worksheet.freeze_panes = "A2"
  # === end modification for timestamp

  # === start modification for timestamp - worksheet_writer.py
  def write_metrics_row(self, metrics: MetricsRow) -> None:
    row_index = self.worksheet.max_row + 1
    font = Font(name="Aptos", size=9)
    alignment = Alignment("left", "center")
    fill_color = CALL_LEVEL_BKGND_COLOR if metrics.is_entire else SAMPLE_LEVEL_BKGND_COLOR
    fill = PatternFill("solid", fgColor=fill_color)

    values = [
      metrics.metadata,
      metrics.session_id,
      metrics.section,
      metrics.ground_truth_text,
      metrics.model_text,
      metrics.wer,
      metrics.hallucination_count,
      metrics.ground_truth_tokens,
      metrics.hallucination_percent,
      metrics.hallucination_text,
      metrics.duration,
      metrics.transcript_density,
    ]

    for col_index, value in enumerate(values, start=1):
      cell = self.worksheet.cell(row_index, col_index, value)
      cell.font = font
      cell.alignment = alignment
      cell.fill = fill
      cell.border = THIN_BORDER

      header_value = self.worksheet.cell(1, col_index).value
      if header_value == WER_COL_NAME:
        cell.number_format = "0.0000"
      elif header_value == HALLUCINATION_PERCENT_COL_NAME:
        cell.number_format = "0.0000"
      elif header_value == TRANSCRIPT_DENSITY_COL_NAME:
        cell.number_format = "0.00"
  # === end modification for timestamp

  # === start modification for timestamp - worksheet_writer.py
  def _write_header(self, has_speaker_column: bool) -> None:
    headers = [METADATA_COL_NAME]
    if has_speaker_column:
      headers.append("Speaker")
    headers.extend([
      AVERAGE_WER_COL_NAME,
      SESSION_COUNT_COL_NAME,
      AVG_HALLUCINATION_PERCENT_COL_NAME,
      AVERAGE_TRX_DENSITY_COL_NAME
    ])

    for col, title in enumerate(headers, start=1):
      cell = self.worksheet.cell(1, col, title)
      cell.font = Font(name="Aptos", size=9, bold=True)
      cell.alignment = Alignment("left", "center")
  # === end modification for timestamp

  #=== start modification for timestamp - worksheet_writer.py
  def write_summary_row(self, summary: SummaryData, row_num: int, has_speaker_column: bool) -> None:
      values = [summary.metadata]
      if has_speaker_column:
          values.append(summary.speaker)
      values.extend([
          summary.average_wer,
          summary.session_count,
          summary.average_hallucination_percent,
          summary.average_transcript_density
      ])

      for col, value in enumerate(values, start=1):
          cell = self.worksheet.cell(row_num, col, value)
          cell.font = Font(name="Aptos", size=9)
          cell.alignment = Alignment("left", "center")
          cell.fill = PatternFill(
              "solid",
              fgColor=CALL_LEVEL_BKGND_COLOR if CALL_LEVEL_GRANULARITY else SAMPLE_LEVEL_BKGND_COLOR
          )
          cell.border = THIN_BORDER

          wer_col = 3 if has_speaker_column else 2
          halluc_col = 5 if has_speaker_column else 4
          density_col = 6 if has_speaker_column else 5

          if col == wer_col or col == halluc_col:
              cell.number_format = "0.0000"
          elif col == density_col:
              cell.number_format = "0.00"
  #=== end modification for timestamp
  
# ======================================================================================================== comparer.py

import os
import sys
from typing import Dict, List, Tuple

from openpyxl import load_workbook
from openpyxl.styles import Alignment, Font
from openpyxl.utils import get_column_letter
from openpyxl.workbook import Workbook
import pandas as pd
import yaml

class Config:
  def __init__(self, config_path: str):
    with open(config_path, 'r') as f:
      self.config = yaml.safe_load(f)

  @property
  def input_directory(self) -> str:
    return self.config['input_directory']

  @property
  def input_filename(self) -> str:
    return self.config['input_filename']

  @property
  def output_directory(self) -> str:
    return self.config['output_directory']

  @property
  def output_filename(self) -> str:
    return self.config['output_filename']

  @property
  def column_widths(self) -> dict:
    return self.config.get('column_widths', {})

class TranscriptNormalizer:
  @staticmethod
  def normalize(text: str) -> List[str]:
    if not isinstance(text, str):
      return []
    from nltk_jiwer_utils import normalize_string

    return normalize_string(text)

  @staticmethod
  def delta_and_ops(left: str, right: str) -> Tuple[int, int, int, int]:
    from nltk_jiwer_utils import get_jiwer_result

    result = get_jiwer_result(left, right)
    substitutions = result.get("substitutions", 0)
    deletions = result.get("deletions", 0)
    insertions = result.get("insertions", 0)
    delta = substitutions + deletions + insertions
    return delta, substitutions, deletions, insertions

  @staticmethod
  def delta(left: str, right: str) -> int:
    differences, _, _, _ = TranscriptNormalizer.delta_and_ops(left, right)
    return differences

class WorkbookReader:
  REQUIRED_COLUMNS = ["speaker", "SeqNumRange", "SeqNum", "Transcript"]

  def __init__(self, input_path: str):
    self.input_path = input_path

  def load_sessions(self) -> Dict[str, Dict[str, pd.DataFrame]]:
    wb = load_workbook(self.input_path, read_only=True, data_only=True)
    sessions = {}
    for sheet_name in wb.sheetnames:
      if ' - ' in sheet_name:
        environment, session_id = [part.strip() for part in sheet_name.split(' - ', 1)]
        if environment.lower() not in ['triton', 'vllm']:
          continue
        if session_id not in sessions:
          sessions[session_id] = {}
        df = pd.read_excel(
          self.input_path,
          sheet_name=sheet_name,
          engine='openpyxl'
        )
        available_cols = {col.lower(): col for col in df.columns}
        selected_data = {}
        for req_col in self.REQUIRED_COLUMNS:
          if req_col.lower() in available_cols:
            actual_col = available_cols[req_col.lower()]
            selected_data[req_col] = df[actual_col]
          else:
            selected_data[req_col] = pd.Series([None] * len(df))
        result_df = pd.DataFrame(selected_data)
        sessions[session_id][environment.lower()] = result_df
    wb.close()
    return sessions

class EnvironmentComparer:
  def __init__(self, sessions: Dict[str, Dict[str, pd.DataFrame]]):
    self.sessions = sessions

  def build_output(self) -> pd.DataFrame:
    all_rows = []
    for session_id, envs in self.sessions.items():
      triton_df = envs.get('triton')
      vllm_df = envs.get('vllm')
      if triton_df is None or vllm_df is None:
        print(f"Warning: Session '{session_id}' missing one environment")
        continue
      triton_dict = {}
      for idx, row in triton_df.iterrows():
        key = (row['speaker'], row['SeqNum'])
        triton_dict[key] = {
          'index': idx,
          'SeqNumRange': row['SeqNumRange'],
          'Transcript': row['Transcript']
        }
      vllm_dict = {}
      for idx, row in vllm_df.iterrows():
        key = (row['speaker'], row['SeqNum'])
        vllm_dict[key] = {
          'index': idx,
          'SeqNumRange': row['SeqNumRange'],
          'Transcript': row['Transcript']
        }
      all_keys = set(triton_dict.keys()) | set(vllm_dict.keys())

      def sort_key(x):
        speaker, seq_num = x
        return (0 if speaker == 'agent0' else 1 if speaker == 'customer0' else 2, seq_num)

      sorted_keys = sorted(all_keys, key=sort_key)
      for key_idx, key in enumerate(sorted_keys, start=1):
        speaker, seq_num = key
        triton_data = triton_dict.get(key)
        vllm_data = vllm_dict.get(key)
        if triton_data and vllm_data:
          delta, substitutions, deletions, insertions = TranscriptNormalizer.delta_and_ops(
            triton_data['Transcript'],
            vllm_data['Transcript']
          )
          from nltk_jiwer_utils import get_jiwer_result

          result = get_jiwer_result(triton_data['Transcript'], vllm_data['Transcript'])
          wer = result.get("wer", 0.0)
        elif triton_data:
          delta, substitutions, deletions, insertions = TranscriptNormalizer.delta_and_ops(
            triton_data['Transcript'], ""
          )
          from nltk_jiwer_utils import get_jiwer_result

          result = get_jiwer_result(triton_data['Transcript'], "")
          wer = result.get("wer", 0.0)
        elif vllm_data:
          delta, substitutions, deletions, insertions = TranscriptNormalizer.delta_and_ops(
            "", vllm_data['Transcript']
          )
          wer = 0.0
        else:
          delta = substitutions = deletions = insertions = 0
          wer = 0.0
        row = {
          'index': len(all_rows) + 1,
          'session_id': session_id,
          'Triton_SeqNum': seq_num if triton_data else None,
          'Triton_SeqNumRange': triton_data['SeqNumRange'] if triton_data else None,
          'Triton_Speaker': speaker if triton_data else None,
          'Triton_Transcript': triton_data['Transcript'] if triton_data else None,
          'Vllm_SeqNum': seq_num if vllm_data else None,
          'Vllm_SeqNumRange': vllm_data['SeqNumRange'] if vllm_data else None,
          'Vllm_Speaker': speaker if vllm_data else None,
          'Vllm_Transcript': vllm_data['Transcript'] if vllm_data else None,
          'Delta': delta,
          'S': substitutions,
          'D': deletions,
          'I': insertions,
          'WER': wer
        }
        all_rows.append(row)
    columns = [
      'index', 'session_id',
      'Triton_SeqNum', 'Triton_SeqNumRange', 'Triton_Speaker', 'Triton_Transcript',
      'Vllm_SeqNum', 'Vllm_SeqNumRange', 'Vllm_Speaker', 'Vllm_Transcript',
      'Delta', 'S', 'D', 'I', 'WER'
    ]
    return pd.DataFrame(all_rows, columns=columns)

class WorkbookWriter:
  def __init__(self, df: pd.DataFrame, output_path: str, column_widths: dict):
    self.df = df
    self.output_path = output_path
    self.column_widths = column_widths

  def write(self):
    output_dir = os.path.dirname(self.output_path)
    if output_dir:
      os.makedirs(output_dir, exist_ok=True)
    wb = Workbook()
    ws = wb.active
    ws.title = 'Comparison'
    ws['C1'].value = "Triton"
    ws['G1'].value = "Vllm"
    ws['K1'].value = "WER"
    display_headers = [
      'index', 'session_id',
      'SeqNum', 'SeqNumRange', 'Speaker', 'Transcript',
      'SeqNum', 'SeqNumRange', 'Speaker', 'Transcript',
      'Delta', 'S', 'D', 'I', 'WER%'
    ]
    for col_idx, header in enumerate(display_headers, start=1):
      ws.cell(row=2, column=col_idx, value=header)
    row_idx = 3
    for _, df_row in self.df.iterrows():
      ws.cell(row=row_idx, column=1, value=df_row['index'])
      ws.cell(row=row_idx, column=2, value=df_row['session_id'])
      ws.cell(row=row_idx, column=3, value=df_row['Triton_SeqNum'])
      ws.cell(row=row_idx, column=4, value=df_row['Triton_SeqNumRange'])
      ws.cell(row=row_idx, column=5, value=df_row['Triton_Speaker'])
      ws.cell(row=row_idx, column=6, value=df_row['Triton_Transcript'])
      ws.cell(row=row_idx, column=7, value=df_row['Vllm_SeqNum'])
      ws.cell(row=row_idx, column=8, value=df_row['Vllm_SeqNumRange'])
      ws.cell(row=row_idx, column=9, value=df_row['Vllm_Speaker'])
      ws.cell(row=row_idx, column=10, value=df_row['Vllm_Transcript'])
      ws.cell(row=row_idx, column=11, value=df_row['Delta'])
      ws.cell(row=row_idx, column=12, value=df_row['S'])
      ws.cell(row=row_idx, column=13, value=df_row['D'])
      ws.cell(row=row_idx, column=14, value=df_row['I'])
      ws.cell(row=row_idx, column=15, value=df_row['WER'])
      row_idx += 1
    aptos_font_bold = Font(name='Aptos', size=9, bold=True)
    aptos_font = Font(name='Aptos', size=9)
    center_alignment = Alignment(horizontal='center', vertical='center')
    for col in range(1, 16):
      cell = ws.cell(row=1, column=col)
      cell.font = aptos_font_bold
      cell.alignment = center_alignment
    for col in range(1, 16):
      cell = ws.cell(row=2, column=col)
      cell.font = aptos_font_bold
    for row in range(3, row_idx):
      for col in range(1, 16):
        ws.cell(row=row, column=col).font = aptos_font
    ws.merge_cells('C1:F1')
    ws['C1'].alignment = center_alignment
    ws['C1'].font = aptos_font_bold
    ws.merge_cells('G1:J1')
    ws['G1'].alignment = center_alignment
    ws['G1'].font = aptos_font_bold
    ws.merge_cells('K1:O1')
    ws['K1'].alignment = center_alignment
    ws['K1'].font = aptos_font_bold
    column_width_map = {
      1: self.column_widths.get('index', 8),
      2: self.column_widths.get('session_id', 20),
      3: self.column_widths.get('Triton_SeqNum', 10),
      4: self.column_widths.get('Triton_SeqNumRange', 15),
      5: self.column_widths.get('Triton_Speaker', 12),
      6: self.column_widths.get('Triton_Transcript', 50),
      7: self.column_widths.get('Vllm_SeqNum', 10),
      8: self.column_widths.get('Vllm_SeqNumRange', 15),
      9: self.column_widths.get('Vllm_Speaker', 12),
      10: self.column_widths.get('Vllm_Transcript', 50),
      11: self.column_widths.get('Delta', 10),
      12: self.column_widths.get('S', 8),
      13: self.column_widths.get('D', 8),
      14: self.column_widths.get('I', 8),
      15: self.column_widths.get('WER', 10)
    }
    for col_idx, width in column_width_map.items():
      col_letter = get_column_letter(col_idx)
      ws.column_dimensions[col_letter].width = width
    ws.freeze_panes = 'A3'
    ws.auto_filter.ref = f"A2:{get_column_letter(len(display_headers))}2"
    wb.save(self.output_path)

class CompareEnvironmentsApp:
  def __init__(self, config_path: str):
    self.config = Config(config_path)

  def run(self):
    input_path = os.path.join(
      self.config.input_directory,
      self.config.input_filename
    )
    output_path = os.path.join(
      self.config.output_directory,
      self.config.output_filename
    )
    html_output_path = os.path.join(
      self.config.output_directory,
      self.config.output_filename.replace('.xlsx', '.html')
    )
    print(f"Reading input from: {input_path}")
    reader = WorkbookReader(input_path)
    sessions = reader.load_sessions()
    print(f"Found {len(sessions)} session(s)")
    print("Comparing environments...")
    comparer = EnvironmentComparer(sessions)
    result_df = comparer.build_output()
    print(f"Generated {len(result_df)} comparison rows")
    print(f"Writing Excel output to: {output_path}")
    writer = WorkbookWriter(result_df, output_path, self.config.column_widths)
    writer.write()
    print(f"Writing HTML output to: {html_output_path}")
    html_writer = HTMLReportWriter(result_df, html_output_path)
    html_writer.write()
    print("Done!")

class HTMLReportWriter:
  def __init__(self, df: pd.DataFrame, output_path: str):
    self.df = df
    self.output_path = output_path

  def get_word_alignments(self, reference: str, hypothesis: str):
    from nltk_jiwer_utils import get_jiwer_result, get_jiwer_alignment

    if not reference and not hypothesis:
      return [], []
    jiwer_result = get_jiwer_result(reference, hypothesis)
    alignment = get_jiwer_alignment(jiwer_result)
    ref_tagged = []
    hyp_tagged = []
    for line in alignment:
      parts = [p.strip() for p in line.split("|")]
      if len(parts) != 3:
        continue
      operation = parts[0].upper()
      ref_word = parts[1]
      hyp_word = parts[2]
      if operation == "CORRECT":
        ref_tagged.append(('correct', ref_word))
        hyp_tagged.append(('correct', hyp_word))
      elif operation == "SUBSTITUTION":
        ref_tagged.append(('substitute', ref_word))
        hyp_tagged.append(('substitute', hyp_word))
      elif operation == "DELETION":
        ref_tagged.append(('delete', ref_word))
        hyp_tagged.append(('delete', '***'))
      elif operation == "INSERTION":
        ref_tagged.append(('insert', '***'))
        hyp_tagged.append(('insert', hyp_word))
    return ref_tagged, hyp_tagged

  def format_transcript(self, tagged_words):
    html_parts = []
    for tag, word in tagged_words:
      if word == '***':
        html_parts.append(f'<span style="color: #999; font-style: italic;">{word}</span>')
      elif tag == 'correct':
        html_parts.append(f'<span style="color: #808080;">{word}</span>')
      elif tag == 'substitute':
        html_parts.append(
          f'<span style="color: #000; background-color: #FF8C00; padding: 2px 4px; border-radius: 3px;">{word}</span>')
      elif tag == 'delete':
        html_parts.append(
          f'<span style="color: #fff; background-color: #DC143C; padding: 2px 4px; border-radius: 3px;">{word}</span>')
      elif tag == 'insert':
        html_parts.append(
          f'<span style="color: #fff; background-color: #1E90FF; padding: 2px 4px; border-radius: 3px;">{word}</span>')
      else:
        html_parts.append(f'<span>{word}</span>')
    return ' '.join(html_parts)

  def write(self):
    html = """<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Transcript Comparison - Triton vs Vllm</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            font-size: 10px;
            margin: 0;
            padding: 0;
            background-color: #f5f5f5;
        }
        .header {
            position: sticky;
            top: 0;
            background-color: #f5f5f5;
            z-index: 100;
            padding: 20px 20px 10px 20px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .content {
            padding: 0 20px 20px 20px;
        }
        h1 {
            color: #333;
            text-align: center;
            margin: 0 0 10px 0;
        }
        .legend {
            text-align: center;
            margin-bottom: 10px;
            padding: 10px;
            background-color: white;
            border-radius: 5px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }
        .legend span {
            margin: 0 15px;
            font-size: 14px;
        }
        .legend .sample-correct {
            color: #808080;
        }
        .legend .sample-substitute {
            color: #000;
            background-color: #FF8C00;
            padding: 2px 6px;
            border-radius: 3px;
        }
        .legend .sample-delete {
            color: #fff;
            background-color: #DC143C;
            padding: 2px 6px;
            border-radius: 3px;
        }
        .legend .sample-insert {
            color: #fff;
            background-color: #1E90FF;
            padding: 2px 6px;
            border-radius: 3px;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            background-color: white;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }
        th {
            background-color: #4CAF50;
            color: white;
            padding: 12px;
            text-align: left;
            font-weight: 600;
            border: 1px dotted #ddd;
            position: sticky;
            top: 120px;
            z-index: 10;
        }
        tr, td {
          line-height: 0.5;
          vertical-align: middle;
        }
        td {
            padding: 2px;
            border: 1px dotted #ddd;
        }
        tr:nth-child(even) {
            background-color: #f9f9f9;
        }
        tr:hover {
            background-color: #f0f0f0;
        }
        .index-col {
            width: 10px;
            text-align: center;
            font-weight: 600;
            color: #666;
        }
        .session-col {
            width: 80px;
            font-weight: 600;
            color: #333;
            text-align: center;
        }
        .speaker-col {
            width: 40px;
            font-weight: 600;
            color: #333;
        }
        .seqrange-col {
            width: 60px;
            text-align: center;
            font-size: 9px;
        }
        .seqrange-mismatch {
            background-color: #FFFF99;
        }
        .transcript-col {
            line-height: 1.6;
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>&xlarr; Triton (Reference GT) vs vLLM &xrarr;</h1>
        <div class="legend">
            <!--span class="sample-correct">Correct</span-->
            <span class="sample-substitute">Substitution</span>
            <span class="sample-delete">Deletion</span>
            <span class="sample-insert">Insertion</span>
            <span style="color: #999; font-style: italic;">*** : Transcript Gap</span>
        </div>
    </div>
    <div class="content">
        <table>
            <thead>
                <tr>
                    <th class="index-col">Index</th>
                    <th class="session-col">Session ID</th>
                    <th class="speaker-col">Speaker</th>
                    <th class="transcript-col">Triton Transcript (Reference GT)</th>
                    <th class="seqrange-col">SeqRT</th>
                    <th class="seqrange-col">SeqRV</th>
                    <th class="transcript-col">vLLM Transcript (Relative to Triton)</th>
                </tr>
            </thead>
            <tbody>
"""

    for _, row in self.df.iterrows():
      index = row['index']
      session_id = row['session_id']
      speaker = row['Triton_Speaker'] or row['Vllm_Speaker'] or 'Unknown'
      triton_text = row['Triton_Transcript'] or ''
      vllm_text = row['Vllm_Transcript'] or ''
      triton_seqrange = str(row['Triton_SeqNumRange']) if pd.notna(row['Triton_SeqNumRange']) else ''
      vllm_seqrange = str(row['Vllm_SeqNumRange']) if pd.notna(row['Vllm_SeqNumRange']) else ''
      seqrange_mismatch = triton_seqrange != vllm_seqrange
      seqrange_class = 'seqrange-col seqrange-mismatch' if seqrange_mismatch else 'seqrange-col'
      ref_tagged, hyp_tagged = self.get_word_alignments(triton_text, vllm_text)
      triton_formatted = self.format_transcript(ref_tagged) if ref_tagged else triton_text
      vllm_formatted = self.format_transcript(hyp_tagged) if hyp_tagged else vllm_text
      html += f"""            <tr>
                <td class="index-col">{index}</td>
                <td class="session-col">{session_id}</td>
                <td class="speaker-col">{speaker}</td>
                <td class="transcript-col">{triton_formatted}</td>
                <td class="{seqrange_class}">{triton_seqrange}</td>
                <td class="{seqrange_class}">{vllm_seqrange}</td>
                <td class="transcript-col">{vllm_formatted}</td>
            </tr>
"""

    html += """        </tbody>
    </table>
    </div>
</body>
</html>"""

    with open(self.output_path, 'w', encoding='utf-8') as f:
      f.write(html)

def main(config_file="config.yaml"):
  try:
    app = CompareEnvironmentsApp(config_file)
    app.run()
    print("Comparison completed successfully!")
  except Exception as e:
    print(f"Error: {e}")
    sys.exit(1)

if __name__ == "__main__":
  main("config.yaml")