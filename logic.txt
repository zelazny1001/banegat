

# === business_inputs_to_monthly.py ===

#business_inputs_to_monthly.py

from __future__ import annotations
import os
from openpyxl import load_workbook, Workbook
from openpyxl.utils import get_column_letter
from openpyxl.styles import Font
from constants import INPUT_DATA_WORKSHEET_NAME, WORKSHEET_PREFIX

def add_input_data_worksheet_with_metadata(monthly_workbook: Workbook, metrics_workbook_paths: list[str]) -> None:
    consolidated_input_worksheet  = monthly_workbook.create_sheet(INPUT_DATA_WORKSHEET_NAME, 0)
    header_written = True
    for metrics_path in metrics_workbook_paths:
        metrics_workbook = load_workbook(metrics_path)
        input_sheet_name = next(name for name in metrics_workbook.sheetnames if name.startswith(WORKSHEET_PREFIX))
        input_worksheet = metrics_workbook[input_sheet_name]
        metadata_value = os.path.splitext(os.path.basename(metrics_path))[0]
        for row_index, row_values in enumerate(input_worksheet.iter_rows(values_only=True), start=1):
            if row_index == 1:
                if header_written:
                    consolidated_input_worksheet.append(["metadata"] + list(row_values))
                    header_written = False
                continue
            if not any((str(cell).strip() if cell is not None else "") for cell in row_values):
                continue
            consolidated_input_worksheet.append([metadata_value] + list(row_values))
    consolidated_input_worksheet.freeze_panes = "A2"
    consolidated_input_worksheet.auto_filter.ref = f"A1:{get_column_letter(consolidated_input_worksheet.max_column)}{consolidated_input_worksheet .max_row}"
    for col in range(1, consolidated_input_worksheet.max_column + 1):
        consolidated_input_worksheet.column_dimensions[get_column_letter(col)].width = 35
    for cell in consolidated_input_worksheet [1]:
        cell.font = Font(name="Aptos", size=9, bold=True)

# === constants.py ===

# constants.py

from __future__ import annotations

USE_HALLUCINATION_FLAGS: bool = False
CODE_IS_BEING_TESTED: bool = True
INCLUDE_CONDITIONS = False

ROOT_DIR: str = "j:/projects/sheet-logic/asr-april-2025-data"#-agent-cust" # asr-april-2025-data"
SPREADSHEET_PREFIX: str = "ASR"
WORKSHEET_PREFIX: str = "ASR"
METRICS_CONDITION_TEMPLATE = "metrics-condition-template.xlsx"
DO_MONTHLY_CONSOLIDATION: bool = True
CALL_LEVEL_GRANULARITY: bool = True # False means sample level granularity
AVERAGING_PERIOD =  "weekly" # "monthly"

SESSION_ID_COL_NAME: str = "session_id"
RAW_TRANSCRIPT_COL_NAME: str = "raw_transcript"
GROUND_TRUTH_COL_NAME: str = "Ground Truth Transcript"
HALLUCINATION_COL_NAME: str = "Hallucination"

INPUT_DATA_WORKSHEET_NAME: str = "input-data"

METRICS_WORKSHEET_NAME: str = "metrics"
AGENT_CUSTOMER_METRICS_WORKSHEET_NAME: str = "agent-customer-metrics"
METADATA_COL_NAME: str = "metadata"
SECTION_COL_NAME: str = "section"
ENTIRE_COL_NAME: str = "entire"
GT_SECTION_TEXT_COL_NAME: str = "gt section"
MODEL_SECTION_TEXT_COL_NAME: str = "model text"
WER_COL_NAME: str = "WER"
HALLUCINATION_COUNT_COL_NAME: str = "Hallucination Count"
GT_TOKS_COL_NAME: str = "GT Toks"
HALLUCINATION_PERCENT_COL_NAME: str = "Hallucination %"

NUMBER_OF_SECTIONS: int = 5
WER_POST_ENDPOINT: str = "https://wer_host:3281/word_error_rate"
WER_ALGORITHM = "nltk"

WEEKLY_SUMMARY_WORKSHEET_NAME: str = "weekly-summary"
MONTHLY_SUMMARY_WORKSHEET_NAME: str = "monthly-summary"

AVERAGE_WER_COL_NAME: str = "AVG_WER"
SESSION_COUNT_COL_NAME: str = "num sessions"
SUMMARY_HALLUCINATION_COUNT_COL_NAME: str = "Hallucination Count"
HALLUCINATION_AVG_COL_NAME: str = "Hallucination Avg"
AVG_HALLUCINATION_PERCENT_COL_NAME: str = "Avg Hallucination %"

CALL_LEVEL_BKGND_COLOR: str = "00FFFF"
SAMPLE_LEVEL_BKGND_COLOR: str = "FFFFFF"
SOURCE_COL_WIDTHS = {"A": 69, "B": 35, "C": 35, "D": 12}
METRICS_HEADER_COL_WIDTHS = {"A": 27, "B": 65, "C": 9, "D": 63, "E": 63, "F": 8, "G": 12, "H": 10, "I": 15}
SUMMARY_COL_WIDTHS = {"A": 30, "B": 13, "C": 16, "D": 22}

# Agent / Customer interaction support

VTYPE_COL_NAME: str = "vtype"
AGENT_VALUE: str = "Agent"
CUSTOMER_VALUE: str = "Customer"

# === data_models.py ===

# data_models.py

from __future__ import annotations
from dataclasses import dataclass, field
from typing import Optional

@dataclass
class TranscriptPair:
    transcript: str
    ground_truth: str

@dataclass
class HallucinationData:
    counts: list[int]
    texts: list[str]

@dataclass
class SessionData:
    session_id: str
    transcript_pairs: list[TranscriptPair]
    hallucination_data: Optional[HallucinationData] = None

@dataclass
class SpeakerSessionData:
    session_id: str
    customer_pairs: list[TranscriptPair] = field(default_factory=list)
    agent_pairs: list[TranscriptPair] = field(default_factory=list)
    customer_hallucinations: Optional[HallucinationData] = None
    agent_hallucinations: Optional[HallucinationData] = None

@dataclass
class MetricsRow:
    metadata: str
    session_id: str
    section: str
    ground_truth_text: str
    model_text: str
    wer: float
    hallucination_count: int
    ground_truth_tokens: int
    hallucination_percent: Optional[float]
    hallucination_text: str
    is_entire: bool = False

@dataclass
class SummaryData:
    metadata: str
    average_wer: float
    session_count: int
    average_hallucination_percent: float
    speaker: Optional[str] = None

# === file_manager.py ===

# file_manager.py

from __future__ import annotations
import os
from typing import Optional
from openpyxl import load_workbook
from constants import SPREADSHEET_PREFIX, WORKSHEET_PREFIX

class FileManager:
  def __init__(self, root_dir: str):
    self.root_dir = root_dir

  def list_input_spreadsheets(self) -> list[str]:
    return sorted(
      os.path.join(self.root_dir, name)
      for name in os.listdir(self.root_dir)
      if name.startswith(f"{SPREADSHEET_PREFIX}_")
      and name.lower().endswith(".xlsx")
      and not name.endswith("_metrics.xlsx")
      and not name.endswith("_monthly_metrics.xlsx")
    )

  def qualifies_for_processing(self, input_path: str) -> tuple[bool, Optional[str]]:
    try:
      workbook = load_workbook(input_path, read_only=True, data_only=True, keep_links=False)
      try:
        worksheet_name = next(
          (n for n in workbook.sheetnames if n.startswith(WORKSHEET_PREFIX)),
          None
        )
        return worksheet_name is not None, worksheet_name
      finally:
        workbook.close()
    except Exception:
      return False, None

  def get_metrics_output_path(self, input_path: str) -> str:
    directory = os.path.dirname(input_path)
    base = os.path.basename(input_path).rsplit(".", 1)[0]
    return os.path.join(directory, f"{base}_metrics.xlsx")

# === main_orchestrator.py ===

# main_orchestrator.py

from __future__ import annotations
from file_manager import FileManager
from workbook_processor import WorkbookProcessor
from monthly_workbook_processor import MonthlyWorkbookProcessor
from constants import ROOT_DIR, SPREADSHEET_PREFIX, DO_MONTHLY_CONSOLIDATION

class ApplicationOrchestrator:
  def __init__(self, root_dir: str):
    self.root_dir = root_dir
    self.file_manager = FileManager(root_dir)
    self.workbook_processor = WorkbookProcessor()
    self.monthly_processor = MonthlyWorkbookProcessor()

  def run(self) -> None:
    metrics_files = self._process_input_files()

    if DO_MONTHLY_CONSOLIDATION and metrics_files:
      self._create_monthly_consolidation(metrics_files)

  def _process_input_files(self) -> list[str]:
    input_files = self.file_manager.list_input_spreadsheets()
    metrics_files: list[str] = []

    for index, input_path in enumerate(input_files, start=1):
      ok, worksheet_name = self.file_manager.qualifies_for_processing(input_path)

      if not ok:
        print(f"{index}/{len(input_files)} Skipping {input_path}: no worksheet starting with {SPREADSHEET_PREFIX}")
        continue

      output_path = self.workbook_processor.process_input_workbook(input_path)

      if output_path:
        metrics_files.append(output_path)
        print(f"{index}/{len(input_files)} Saved metrics and summaries to {output_path}")

    return metrics_files

  def _create_monthly_consolidation(self, metrics_files: list[str]) -> None:
    monthly_path, monthly_workbook = self.monthly_processor.create_monthly_workbook(
      self.root_dir,
      metrics_files,
      SPREADSHEET_PREFIX
    )
    print(f"Saved monthly consolidated metrics to {monthly_path}")

def main() -> None:
  orchestrator = ApplicationOrchestrator(ROOT_DIR)
  orchestrator.run()

if __name__ == "__main__":
  main()

# === metrics_calculator.py ===

# metrics_calculator.py

from __future__ import annotations
import re
import random
import requests
from typing import Tuple
from data_models import TranscriptPair, MetricsRow
from constants import CODE_IS_BEING_TESTED, WER_POST_ENDPOINT, NUMBER_OF_SECTIONS

class TextPreprocessor:
  @staticmethod
  def preprocess(text: str) -> str:
    if not text:
      return ""
    lowered = str(text).lower()
    lowered = re.sub(r"[.,\-?â€¦]", " ", lowered)
    lowered = re.sub(r"\{[^}]*\}", "", lowered)
    lowered = re.sub(r"[\[\]]", "", lowered)
    return re.sub(r"\s+", " ", lowered).strip()

class WERCalculator:
  def __init__(self, endpoint: str):
    self.endpoint = endpoint
    self.preprocessor = TextPreprocessor()

  def calculate(self, ground_truth: str, transcript: str) -> Tuple[float, int]:
    if CODE_IS_BEING_TESTED:
      return round(random.uniform(0, 100), 4), len(ground_truth.split())

    try:
      response = requests.post(
        self.endpoint,
        json={"groundTruth": ground_truth, "transcript": transcript},
        verify=False,
        timeout=10
      )
      data = response.json()
      return round(float(data[0]), 4), int(data[1])
    except Exception:
      return float("nan"), None

  def calculate_for_pairs(self, pairs: list[TranscriptPair]) -> Tuple[str, str, float, int]:
    ground_truth_joined = " ".join(
      self.preprocessor.preprocess(p.ground_truth) for p in pairs
    )
    transcript_joined = " ".join(
      self.preprocessor.preprocess(p.transcript) for p in pairs
    )
    wer, tokens = self.calculate(ground_truth_joined, transcript_joined)
    return ground_truth_joined, transcript_joined, wer, tokens

class SectionSplitter:
  @staticmethod
  def compute_spans(total_items: int, section_count: int) -> list[tuple[int, int]]:
    if total_items == 0 or section_count <= 0:
      return []

    base_size = total_items // section_count
    remainder = total_items % section_count
    spans: list[tuple[int, int]] = []
    start = 0

    for i in range(1, section_count + 1):
      size = base_size + (1 if i <= remainder else 0)
      if size == 0:
        break
      end = start + size
      spans.append((start, end))
      start = end

    return spans

class MetricsCalculator:
  def __init__(self):
    self.wer_calculator = WERCalculator(WER_POST_ENDPOINT)
    self.section_splitter = SectionSplitter()

  def calculate_metrics_for_section(
      self,
      metadata: str,
      session_id: str,
      section_label: str,
      pairs: list[TranscriptPair],
      hallucination_counts: list[int],
      hallucination_texts: list[str],
      is_entire: bool = False
  ) -> MetricsRow:
    if not pairs:
      return MetricsRow(
        metadata=metadata,
        session_id=session_id,
        section=section_label,
        ground_truth_text="",
        model_text="",
        wer=float("nan"),
        hallucination_count=0,
        ground_truth_tokens=0,
        hallucination_percent=None,
        hallucination_text="",
        is_entire=is_entire
      )

    gt_text, model_text, wer, gt_tokens = self.wer_calculator.calculate_for_pairs(pairs)
    hallucination_total = sum(hallucination_counts)
    hallucination_percent = (100 * hallucination_total / gt_tokens) if gt_tokens else None
    hallucination_text = " ".join(hallucination_texts)

    return MetricsRow(
      metadata=metadata,
      session_id=session_id,
      section=section_label,
      ground_truth_text=gt_text,
      model_text=model_text,
      wer=wer,
      hallucination_count=hallucination_total,
      ground_truth_tokens=gt_tokens,
      hallucination_percent=hallucination_percent,
      hallucination_text=hallucination_text,
      is_entire=is_entire
    )

  def calculate_section_metrics(
      self,
      metadata: str,
      session_id: str,
      pairs: list[TranscriptPair],
      hallucination_counts: list[int],
      hallucination_texts: list[str]
  ) -> list[MetricsRow]:
    spans = self.section_splitter.compute_spans(len(pairs), NUMBER_OF_SECTIONS)
    metrics: list[MetricsRow] = []

    for section_number, (start, end) in enumerate(spans, start=1):
      section_pairs = pairs[start:end]
      section_halluc_counts = hallucination_counts[start:end]
      section_halluc_texts = hallucination_texts[start:end]

      metrics.append(
        self.calculate_metrics_for_section(
          metadata,
          session_id,
          section_number,
          section_pairs,
          section_halluc_counts,
          section_halluc_texts,
          is_entire=False
        )
      )

    return metrics

# === monthly_workbook_processor.py ===

# monthly_workbook_processor.py

from __future__ import annotations
import os
import re
from datetime import datetime
from openpyxl import load_workbook, Workbook
from openpyxl.styles import Font, Alignment
from openpyxl.utils import get_column_letter
from worksheet_reader import WorksheetReader
from summary_calculator import SummaryCalculator
from worksheet_writer import SummaryWorksheetWriter
from constants import (
  WORKSHEET_PREFIX,
  METRICS_WORKSHEET_NAME,
  AGENT_CUSTOMER_METRICS_WORKSHEET_NAME,
  INPUT_DATA_WORKSHEET_NAME,
  MONTHLY_SUMMARY_WORKSHEET_NAME,
  METRICS_HEADER_COL_WIDTHS,
)

class MonthlyWorkbookProcessor:
  def __init__(self):
    self.summary_calculator = SummaryCalculator()

  def create_monthly_workbook(
      self,
      root_dir: str,
      metrics_paths: list[str],
      prefix: str
  ) -> tuple[str, Workbook]:
    monthly_path = self._get_monthly_output_path(root_dir, metrics_paths, prefix)

    if os.path.exists(monthly_path):
      os.remove(monthly_path)

    has_vtype = self._check_vtype_presence(metrics_paths)

    monthly_workbook = Workbook()
    del monthly_workbook[monthly_workbook.sheetnames[0]]

    self._add_consolidated_input_data(monthly_workbook, metrics_paths)
    self._add_consolidated_metrics(monthly_workbook, metrics_paths, has_vtype)
    self._add_monthly_summary(monthly_workbook, has_vtype)

    monthly_workbook.save(monthly_path)
    return monthly_path, monthly_workbook

  def _get_monthly_output_path(self, root_dir: str, metrics_paths: list[str], prefix: str) -> str:
    dates = []

    for metrics_path in metrics_paths:
      if '_week_of_' in metrics_path:
        _, start, end, year = self._parse_weekly_format(metrics_path)
        dates.append((start, end, year))
      else:
        base = os.path.basename(metrics_path).rsplit(".", 1)[0]
        parts = base.split("_")
        rng, year = parts[1], parts[2]
        start, end = re.split(r"thru|-", rng, maxsplit=1)
        dates.append((start, end, year))

    earliest = min(d[0] for d in dates)
    latest = max(d[1] for d in dates)
    year = dates[0][2]
    filename = f"{prefix}_{earliest}thru{latest}_{year}_monthly_metrics.xlsx"
    return os.path.join(root_dir, filename)

  def _parse_weekly_format(self, path: str) -> tuple[str, str, str, str]:
    earliest = path[-17:-13]
    latest = path[-17:-13]
    year = str(datetime.now().year)
    return path, earliest, latest, year

  def _check_vtype_presence(self, metrics_paths: list[str]) -> bool:
    for path in metrics_paths:
      try:
        workbook = load_workbook(path, read_only=True, data_only=True, keep_links=False)
        try:
          worksheet_name = next((n for n in workbook.sheetnames if n.startswith(WORKSHEET_PREFIX)), None)
          if worksheet_name:
            worksheet = workbook[worksheet_name]
            reader = WorksheetReader(worksheet)
            if reader.has_vtype_column():
              return True
        finally:
          workbook.close()
      except Exception:
        continue
    return False

  def _add_consolidated_input_data(self, monthly_workbook: Workbook, metrics_paths: list[str]) -> None:
    from business_inputs_to_monthly import add_input_data_worksheet_with_metadata
    add_input_data_worksheet_with_metadata(monthly_workbook, metrics_paths)

    from speaker_metrics_styling import style_input_data_worksheet
    input_data_ws = monthly_workbook[monthly_workbook.sheetnames[0]]
    style_input_data_worksheet(input_data_ws)

  def _add_consolidated_metrics(
      self,
      monthly_workbook: Workbook,
      metrics_paths: list[str],
      has_vtype: bool
  ) -> None:
    sheet_name = AGENT_CUSTOMER_METRICS_WORKSHEET_NAME if has_vtype else METRICS_WORKSHEET_NAME
    monthly_metrics_ws = monthly_workbook.create_sheet(sheet_name)

    first = True
    for metrics_path in metrics_paths:
      metrics_wb = load_workbook(metrics_path)
      metrics_ws = metrics_wb[METRICS_WORKSHEET_NAME]

      for i, row_values in enumerate(metrics_ws.iter_rows(values_only=True), start=1):
        if i == 1 and not first:
          continue
        monthly_metrics_ws.append(row_values)
      first = False

    from speaker_metrics_styling import apply_agent_customer_metrics_styling
    apply_agent_customer_metrics_styling(monthly_metrics_ws)

  def _add_monthly_summary(self, monthly_workbook: Workbook, has_vtype: bool) -> None:
    metrics_ws = monthly_workbook[
      AGENT_CUSTOMER_METRICS_WORKSHEET_NAME if has_vtype else METRICS_WORKSHEET_NAME
    ]

    summaries = self.summary_calculator.calculate_overall_summary(metrics_ws)

    writer = SummaryWorksheetWriter(monthly_workbook, MONTHLY_SUMMARY_WORKSHEET_NAME)
    writer.create_worksheet(has_speaker_column=has_vtype)

    for row_num, summary in enumerate(summaries, start=2):
      writer.write_summary_row(summary, row_num, has_speaker_column=has_vtype)

    from speaker_metrics_styling import style_monthly_summary_worksheet
    style_monthly_summary_worksheet(writer.worksheet, has_vtype)

# === overall_summary.py ===

# overall_summary.py

from __future__ import annotations
from openpyxl.worksheet.worksheet import Worksheet
from summary_calculator import SummaryCalculator
from worksheet_writer import SummaryWorksheetWriter
from constants import MONTHLY_SUMMARY_WORKSHEET_NAME, SUMMARY_COL_WIDTHS

def add_overall_summary_sheet(workbook, metrics_worksheet: Worksheet) -> None:
  """Compatibility wrapper for existing code that uses functional approach"""
  calculator = SummaryCalculator()
  summaries = calculator.calculate_overall_summary(metrics_worksheet)
  has_speakers = calculator.has_speaker_sections(metrics_worksheet)

  writer = SummaryWorksheetWriter(workbook, MONTHLY_SUMMARY_WORKSHEET_NAME)
  writer.create_worksheet(has_speaker_column=has_speakers)

  for row_num, summary in enumerate(summaries, start=2):
    writer.write_summary_row(summary, row_num, has_speaker_column=has_speakers)

  for col_letter, width in SUMMARY_COL_WIDTHS.items():
    writer.worksheet.column_dimensions[col_letter].width = width

# === session_processor.py ===

# session_processor.py

from __future__ import annotations
from data_models import SessionData, SpeakerSessionData, MetricsRow, TranscriptPair
from worksheet_reader import WorksheetReader
from metrics_calculator import MetricsCalculator
from constants import ENTIRE_COL_NAME, CUSTOMER_VALUE, AGENT_VALUE, NUMBER_OF_SECTIONS

class SessionProcessor:
  def __init__(self, reader: WorksheetReader, calculator: MetricsCalculator):
    self.reader = reader
    self.calculator = calculator

  def process_session(self, session: SessionData, metadata: str) -> list[MetricsRow]:
    hallucination_data = self.reader.read_hallucination_data(session.session_id)

    metrics: list[MetricsRow] = []

    entire_metric = self.calculator.calculate_metrics_for_section(
      metadata,
      session.session_id,
      ENTIRE_COL_NAME,
      session.transcript_pairs,
      hallucination_data.counts,
      hallucination_data.texts,
      is_entire=True
    )
    metrics.append(entire_metric)

    section_metrics = self.calculator.calculate_section_metrics(
      metadata,
      session.session_id,
      session.transcript_pairs,
      hallucination_data.counts,
      hallucination_data.texts
    )
    metrics.extend(section_metrics)

    return metrics

class SpeakerSessionProcessor:
  def __init__(self, reader: WorksheetReader, calculator: MetricsCalculator):
    self.reader = reader
    self.calculator = calculator

  def process_speaker_session(
      self,
      session: SpeakerSessionData,
      metadata: str
  ) -> list[MetricsRow]:
    metrics: list[MetricsRow] = []

    for speaker_type, pairs in [
      (CUSTOMER_VALUE, session.customer_pairs),
      (AGENT_VALUE, session.agent_pairs)
    ]:
      hallucination_data = self.reader.read_hallucination_data(
        session.session_id,
        vtype=speaker_type
      )

      entire_metric = self.calculator.calculate_metrics_for_section(
        metadata,
        session.session_id,
        speaker_type,
        pairs,
        hallucination_data.counts,
        hallucination_data.texts,
        is_entire=True
      )
      metrics.append(entire_metric)

      if pairs:
        section_metrics = self._process_speaker_sections(
          metadata,
          session.session_id,
          speaker_type,
          pairs,
          hallucination_data.counts,
          hallucination_data.texts
        )
        metrics.extend(section_metrics)

    return metrics

  def _process_speaker_sections(
      self,
      metadata: str,
      session_id: str,
      speaker_type: str,
      pairs: list[TranscriptPair],
      hallucination_counts: list[int],
      hallucination_texts: list[str]
  ) -> list[MetricsRow]:
    spans = self.calculator.section_splitter.compute_spans(len(pairs), NUMBER_OF_SECTIONS)
    metrics: list[MetricsRow] = []

    for section_number, (start, end) in enumerate(spans, start=1):
      section_pairs = pairs[start:end]
      section_halluc_counts = hallucination_counts[start:end]
      section_halluc_texts = hallucination_texts[start:end]
      section_label = f"{speaker_type}{section_number}"

      metrics.append(
        self.calculator.calculate_metrics_for_section(
          metadata,
          session_id,
          section_label,
          section_pairs,
          section_halluc_counts,
          section_halluc_texts,
          is_entire=False
        )
      )

    return metrics

# === speaker_metrics_styling.py ===

# speaker_metrics_styling.py
# Styling functions specific to agent-customer metrics
# Can be easily removed/modified without affecting core functionality

from __future__ import annotations
from openpyxl.worksheet.worksheet import Worksheet
from openpyxl.styles import Font, Alignment, PatternFill, Border, Side
from openpyxl.utils import get_column_letter
from constants import (
  CALL_LEVEL_BKGND_COLOR,
  SAMPLE_LEVEL_BKGND_COLOR,
  CUSTOMER_VALUE,
  AGENT_VALUE,
  WER_COL_NAME,
  HALLUCINATION_PERCENT_COL_NAME,
  METRICS_HEADER_COL_WIDTHS,
)

THIN_SIDE = Side(border_style="thin", color="D3D3D3")
THIN_BORDER = Border(top=THIN_SIDE, bottom=THIN_SIDE, left=THIN_SIDE, right=THIN_SIDE)

def apply_agent_customer_metrics_styling(worksheet: Worksheet) -> None:
  """Apply styling to agent-customer-metrics worksheet in monthly workbook"""
  style_header_row(worksheet)
  apply_freeze_and_filter(worksheet)
  set_column_widths(worksheet)
  format_data_cells(worksheet)

def style_header_row(worksheet: Worksheet) -> None:
  """Style the header row with bold font"""
  for cell in worksheet[1]:
    cell.font = Font(name="Aptos", size=9, bold=True)
    cell.alignment = Alignment("left", "center")

def apply_freeze_and_filter(worksheet: Worksheet) -> None:
  """Apply freeze panes and auto filter"""
  worksheet.freeze_panes = "A2"
  worksheet.auto_filter.ref = f"A1:{get_column_letter(worksheet.max_column)}{worksheet.max_row}"

def set_column_widths(worksheet: Worksheet) -> None:
  """Set column widths from constants"""
  for col_letter, width in METRICS_HEADER_COL_WIDTHS.items():
    worksheet.column_dimensions[col_letter].width = width

def format_data_cells(worksheet: Worksheet) -> None:
  """Format data cells with background colors, borders, and number formats"""
  header_map = {c.value: idx for idx, c in enumerate(worksheet[1], start=1)}
  wer_index = header_map.get(WER_COL_NAME, -1) - 1
  hallucination_percent_index = header_map.get(HALLUCINATION_PERCENT_COL_NAME, -1) - 1
  section_index = header_map.get("section", -1) - 1

  for row in worksheet.iter_rows(min_row=2):
    if section_index >= 0 and len(row) > section_index:
      section_value = row[section_index].value
      is_speaker_level = section_value in (CUSTOMER_VALUE, AGENT_VALUE, "entire")
      background_color = CALL_LEVEL_BKGND_COLOR if is_speaker_level else SAMPLE_LEVEL_BKGND_COLOR
    else:
      background_color = SAMPLE_LEVEL_BKGND_COLOR

    for cell in row:
      cell.fill = PatternFill("solid", fgColor=background_color)
      cell.border = THIN_BORDER

    if wer_index >= 0 and len(row) > wer_index and row[wer_index].value is not None:
      row[wer_index].number_format = "0.00"

    if hallucination_percent_index >= 0 and len(row) > hallucination_percent_index and row[
      hallucination_percent_index].value is not None:
      row[hallucination_percent_index].number_format = "0.0000"

def style_input_data_worksheet(worksheet: Worksheet) -> None:
  """Apply styling to input-data worksheet in monthly workbook"""
  worksheet.freeze_panes = "A2"
  worksheet.auto_filter.ref = f"A1:{get_column_letter(worksheet.max_column)}{worksheet.max_row}"

  for col in range(1, worksheet.max_column + 1):
    worksheet.column_dimensions[get_column_letter(col)].width = 35

  for cell in worksheet[1]:
    cell.font = Font(name="Aptos", size=9, bold=True)

def style_monthly_summary_worksheet(worksheet: Worksheet, has_speaker_column: bool) -> None:
  """Apply styling to monthly-summary worksheet"""
  from constants import SUMMARY_COL_WIDTHS

  for col_letter, width in SUMMARY_COL_WIDTHS.items():
    worksheet.column_dimensions[col_letter].width = width

  for cell in worksheet[1]:
    cell.font = Font(name="Aptos", size=9, bold=True)
    cell.alignment = Alignment("left", "center")

  wer_col = 3 if has_speaker_column else 2
  hallucination_col = 5 if has_speaker_column else 4

  for row in worksheet.iter_rows(min_row=2):
    for cell in row:
      cell.border = THIN_BORDER

    if len(row) > wer_col - 1 and row[wer_col - 1].value is not None:
      row[wer_col - 1].number_format = "0.0000"

    if len(row) > hallucination_col - 1 and row[hallucination_col - 1].value is not None:
      row[hallucination_col - 1].number_format = "0.0000"

# === styling.py ===

#styling.py

from __future__ import annotations
from openpyxl.worksheet.worksheet import Worksheet
from openpyxl.styles import Font, Alignment, PatternFill, Border, Side
from openpyxl.utils import get_column_letter
from constants import (
    CALL_LEVEL_BKGND_COLOR,
    SAMPLE_LEVEL_BKGND_COLOR,
    ENTIRE_COL_NAME,
    WER_COL_NAME,
    HALLUCINATION_PERCENT_COL_NAME,
    SOURCE_COL_WIDTHS,
    METRICS_HEADER_COL_WIDTHS,
)

THIN_SIDE = Side(border_style="thin", color="D3D3D3")
THIN_BORDER = Border(top=THIN_SIDE, bottom=THIN_SIDE, left=THIN_SIDE, right=THIN_SIDE)

def set_column_widths_by_letters(worksheet: Worksheet, letter_to_width: dict[str, float]) -> None:
    for letter, width in letter_to_width.items():
        worksheet.column_dimensions[letter].width = width

def style_copied_input_worksheet(worksheet: Worksheet) -> None:
    set_column_widths_by_letters(worksheet, SOURCE_COL_WIDTHS)
    worksheet.freeze_panes = "A2"
    worksheet.auto_filter.ref = f"A1:D{worksheet.max_row}"
    for cell in worksheet[1]:
        cell.font = Font(name="Aptos", size=9, bold=True)

def style_metrics_header(worksheet: Worksheet) -> None:
    for cell in worksheet[1]:
        cell.font = Font(name="Aptos", size=9, bold=True)
        cell.alignment = Alignment("left", "center")
    worksheet.freeze_panes = "A2"
    worksheet.auto_filter.ref = f"A1:{get_column_letter(worksheet.max_column)}{worksheet.max_row}"
    set_column_widths_by_letters(worksheet, METRICS_HEADER_COL_WIDTHS)

def style_metrics_columns(worksheet: Worksheet) -> None:
    for col_index, width in {1: 27, 2: 65, 3: 9, 4: 63, 5: 63, 6: 9, 7: 12, 8: 10, 9: 15}.items():
        worksheet.column_dimensions[get_column_letter(col_index)].width = width
    worksheet.auto_filter.ref = f"A1:I{worksheet.max_row}"

def format_metrics_cells(worksheet: Worksheet) -> None:
    header_map = {c.value: idx for idx, c in enumerate(worksheet[1], start=1)}
    wer_index = header_map[WER_COL_NAME] - 1
    hallucination_percent_index = header_map[HALLUCINATION_PERCENT_COL_NAME] - 1
    section_index = header_map["section"] - 1
    for row in worksheet.iter_rows(min_row=2):
        if row[wer_index].value is not None:
            row[wer_index].number_format = "0.00"
        if row[hallucination_percent_index].value is not None:
            row[hallucination_percent_index].number_format = "0.0000"
        background_color = CALL_LEVEL_BKGND_COLOR if row[section_index].value == ENTIRE_COL_NAME else SAMPLE_LEVEL_BKGND_COLOR
        for cell in row:
            cell.fill = PatternFill("solid", fgColor=background_color)
            cell.border = THIN_BORDER

def set_weekly_summary_column_widths(worksheet: Worksheet) -> None:
    widths = [20, 9, 12, 16]
    for col_index, width in enumerate(widths, start=1):
        worksheet.column_dimensions[get_column_letter(col_index)].width = width


# === summary_calculator.py ===

# summary_calculator.py

from __future__ import annotations
import re
from datetime import datetime
from openpyxl.worksheet.worksheet import Worksheet
from data_models import SummaryData
from constants import (
  METADATA_COL_NAME,
  WER_COL_NAME,
  HALLUCINATION_PERCENT_COL_NAME,
  SECTION_COL_NAME,
  ENTIRE_COL_NAME,
  CUSTOMER_VALUE,
  AGENT_VALUE,
  CALL_LEVEL_GRANULARITY,
  SPREADSHEET_PREFIX,
)

class MetadataNormalizer:
  @staticmethod
  def normalize(rows: list[list[str]], meta_index: int, prefix: str) -> str:
    if not rows or not rows[0]:
      return f"{prefix}_unknown"

    if '_week_of_' in rows[0][meta_index]:
      return MetadataNormalizer._normalize_week_based(rows, prefix)

    metas = [r[meta_index] for r in rows if len(r) > meta_index and r[meta_index]]
    if not metas:
      return f"{prefix}_unknown"

    parts = [re.search(r"_(\d{4})(?:thru|-)(\d{4})_(\d{4})", m) for m in metas if m]
    parts = [p for p in parts if p]

    if not parts:
      return f"{prefix}_unknown"

    earliest = min(p.group(1) for p in parts)
    latest = max(p.group(2) for p in parts)
    year = parts[0].group(3)
    return f"{prefix}_{earliest}-{latest}_{year}"

  @staticmethod
  def _normalize_week_based(rows: list[list[str]], prefix: str) -> str:
    month_day = rows[0][0][-4:]
    year = datetime.now().year
    return f"{prefix}_{month_day}_{year}"

class SummaryCalculator:
  def __init__(self):
    self.normalizer = MetadataNormalizer()

  def has_speaker_sections(self, metrics_worksheet: Worksheet) -> bool:
    header_map = {c.value: idx for idx, c in enumerate(metrics_worksheet[1], start=1)}
    section_index = header_map[SECTION_COL_NAME] - 1

    for row in metrics_worksheet.iter_rows(min_row=2, max_row=10, values_only=True):
      section_value = row[section_index]
      if section_value in (CUSTOMER_VALUE, AGENT_VALUE):
        return True
    return False

  def calculate_overall_summary(self, metrics_worksheet: Worksheet) -> list[SummaryData]:
    header_map = {c.value: idx for idx, c in enumerate(metrics_worksheet[1], start=1)}
    rows = list(metrics_worksheet.iter_rows(min_row=2, values_only=True))

    wer_index = header_map[WER_COL_NAME] - 1
    hallucination_percent_index = header_map[HALLUCINATION_PERCENT_COL_NAME] - 1
    section_index = header_map[SECTION_COL_NAME] - 1
    metadata_index = header_map[METADATA_COL_NAME] - 1

    has_speakers = self.has_speaker_sections(metrics_worksheet)

    if has_speakers:
      return self._calculate_speaker_summary(
        rows, wer_index, hallucination_percent_index, section_index, metadata_index
      )
    else:
      return self._calculate_non_speaker_summary(
        rows, wer_index, hallucination_percent_index, section_index, metadata_index
      )

  def _calculate_speaker_summary(
      self,
      rows: list,
      wer_index: int,
      hallucination_percent_index: int,
      section_index: int,
      metadata_index: int
  ) -> list[SummaryData]:
    summaries: list[SummaryData] = []

    for speaker in [CUSTOMER_VALUE, AGENT_VALUE]:
      if CALL_LEVEL_GRANULARITY:
        wer_values = [
          row[wer_index] for row in rows
          if row[section_index] == speaker and isinstance(row[wer_index], (int, float))
        ]
        hallucination_values = [
          row[hallucination_percent_index] for row in rows
          if row[section_index] == speaker and isinstance(row[hallucination_percent_index], (int, float))
        ]
      else:
        wer_values = [
          row[wer_index] for row in rows
          if isinstance(row[section_index], str) and row[section_index].startswith(speaker)
             and row[section_index] != speaker and isinstance(row[wer_index], (int, float))
        ]
        hallucination_values = [
          row[hallucination_percent_index] for row in rows
          if isinstance(row[section_index], str) and row[section_index].startswith(speaker)
             and row[section_index] != speaker and isinstance(row[hallucination_percent_index], (int, float))
        ]

      average_wer = sum(wer_values) / len(wer_values) if wer_values else 0.0
      average_hallucination = sum(hallucination_values) / len(hallucination_values) if hallucination_values else 0.0
      session_count = sum(1 for row in rows if row[section_index] == speaker)
      normalized_meta = self.normalizer.normalize(rows, metadata_index, SPREADSHEET_PREFIX)

      summaries.append(SummaryData(
        metadata=normalized_meta,
        average_wer=average_wer,
        session_count=session_count,
        average_hallucination_percent=average_hallucination,
        speaker=speaker
      ))

    return summaries

  def _calculate_non_speaker_summary(
      self,
      rows: list,
      wer_index: int,
      hallucination_percent_index: int,
      section_index: int,
      metadata_index: int
  ) -> list[SummaryData]:
    if CALL_LEVEL_GRANULARITY:
      wer_values = [
        row[wer_index] for row in rows
        if row[section_index] == ENTIRE_COL_NAME and isinstance(row[wer_index], (int, float))
      ]
      hallucination_values = [
        row[hallucination_percent_index] for row in rows
        if row[section_index] == ENTIRE_COL_NAME and isinstance(row[hallucination_percent_index], (int, float))
      ]
    else:
      wer_values = [
        row[wer_index] for row in rows
        if row[section_index] != ENTIRE_COL_NAME and isinstance(row[wer_index], (int, float))
      ]
      hallucination_values = [
        row[hallucination_percent_index] for row in rows
        if row[section_index] != ENTIRE_COL_NAME and isinstance(row[hallucination_percent_index], (int, float))
      ]

    average_wer = sum(wer_values) / len(wer_values) if wer_values else 0.0
    average_hallucination = sum(hallucination_values) / len(hallucination_values) if hallucination_values else 0.0
    normalized_meta = self.normalizer.normalize(rows, metadata_index, SPREADSHEET_PREFIX)
    session_count = sum(1 for row in rows if row[section_index] == ENTIRE_COL_NAME)

    return [SummaryData(
      metadata=normalized_meta,
      average_wer=average_wer,
      session_count=session_count,
      average_hallucination_percent=average_hallucination
    )]

# === weekly_summary.py ===

# weekly_summary.py

from __future__ import annotations
from collections import defaultdict
from openpyxl.worksheet.worksheet import Worksheet
from openpyxl.styles import Font, PatternFill
from constants import (
  METADATA_COL_NAME,
  AVERAGE_WER_COL_NAME,
  SESSION_COUNT_COL_NAME,
  AVG_HALLUCINATION_PERCENT_COL_NAME,
  ENTIRE_COL_NAME,
  WER_COL_NAME,
  HALLUCINATION_PERCENT_COL_NAME,
  WEEKLY_SUMMARY_WORKSHEET_NAME,
  AVERAGING_PERIOD,
  SPREADSHEET_PREFIX,
  CALL_LEVEL_BKGND_COLOR,
)
from styling import set_weekly_summary_column_widths

def add_weekly_summary_sheet(workbook) -> Worksheet:
  if WEEKLY_SUMMARY_WORKSHEET_NAME in workbook.sheetnames:
    del workbook[WEEKLY_SUMMARY_WORKSHEET_NAME]
  return workbook.create_sheet(WEEKLY_SUMMARY_WORKSHEET_NAME)

def write_weekly_summary(metrics_worksheet: Worksheet, summary_worksheet: Worksheet) -> None:
  write_weekly_summary_header(summary_worksheet)
  weekly_summaries = extract_metadata_groups(metrics_worksheet)
  write_weekly_summary_rows(summary_worksheet, weekly_summaries, start_row=3)
  header_map = {c.value: idx for idx, c in enumerate(summary_worksheet[1], start=1)}
  meta_index = header_map[METADATA_COL_NAME] - 1
  avg_wer_index = header_map[AVERAGE_WER_COL_NAME] - 1
  avg_hallucination_index = header_map[AVG_HALLUCINATION_PERCENT_COL_NAME] - 1
  session_index = header_map[SESSION_COUNT_COL_NAME] - 1
  summaries_from_sheet: dict[str, list[tuple[float, float, float]]] = {}
  for row in summary_worksheet.iter_rows(min_row=3, values_only=True):
    meta_label = row[meta_index]
    if not meta_label:
      continue
    w = row[avg_wer_index]
    h = row[avg_hallucination_index]
    s = row[session_index]
    summaries_from_sheet.setdefault(meta_label, []).append((w, s, h))
  write_weekly_summary_final_row(summary_worksheet, summaries_from_sheet)
  set_weekly_summary_column_widths(summary_worksheet)

def write_weekly_summary_header(summary_worksheet: Worksheet) -> None:
  titles = [METADATA_COL_NAME, AVERAGE_WER_COL_NAME, SESSION_COUNT_COL_NAME, AVG_HALLUCINATION_PERCENT_COL_NAME]
  for index, title in enumerate(titles, start=1):
    cell = summary_worksheet.cell(1, index, title)
    cell.font = Font(name="Aptos", size=9, bold=True)

def extract_metadata_groups(metrics_worksheet: Worksheet) -> dict[str, list[tuple[float, float]]]:
  header_map = {c.value: idx for idx, c in enumerate(metrics_worksheet[1], start=1)}
  metadata_index = header_map[METADATA_COL_NAME] - 1
  wer_index = header_map[WER_COL_NAME] - 1
  hallucination_percent_index = header_map[HALLUCINATION_PERCENT_COL_NAME] - 1
  section_index = header_map["section"] - 1
  groups = defaultdict(list)
  for row in metrics_worksheet.iter_rows(min_row=2, values_only=True):
    if row[section_index] == ENTIRE_COL_NAME:
      metadata_value = str(row[metadata_index])
      wer_value = row[wer_index]
      hallucination_value = row[hallucination_percent_index]
      if wer_value is not None:
        groups[metadata_value].append((wer_value, hallucination_value))
  return groups

def write_weekly_summary_rows(summary_worksheet: Worksheet, summaries: dict[str, list[tuple[float, float]]],
                              start_row: int) -> None:
  for row_offset, (metadata_value, rows) in enumerate(summaries.items(), start=start_row):
    wer_values = [w for w, _ in rows]
    hallucination_values = [h for _, h in rows if h is not None]
    average_wer = round(sum(wer_values) / len(wer_values), 4) if wer_values else None
    average_hallucination = round(sum(hallucination_values) / len(hallucination_values),
                                  5) if hallucination_values else None
    count = len(wer_values)
    summary_worksheet.cell(row_offset, 1, metadata_value)
    summary_worksheet.cell(row_offset, 2, average_wer)
    summary_worksheet.cell(row_offset, 3, count)
    summary_worksheet.cell(row_offset, 4, average_hallucination)
    for col in range(1, 5):
      summary_worksheet.cell(row_offset, col).font = Font(name="Aptos", size=9)

def write_weekly_summary_final_row(summary_worksheet: Worksheet,
                                   summaries: dict[str, list[tuple[float, float, float]]]) -> None:
  all_rows = []
  for metadata_value, rows in summaries.items():
    for wer, sessions, hallucinations in rows:
      all_rows.append((metadata_value, wer, sessions, hallucinations))

  wer_values = [row[1] for row in all_rows if isinstance(row[1], (int, float))]
  average_wer = (sum(wer_values) / len(wer_values)) if wer_values else None
  session_values = [row[2] for row in all_rows if isinstance(row[2], (int, float))]
  total_sessions = int(sum(session_values)) if session_values else 0
  hallucination_values = [row[3] for row in all_rows if isinstance(row[3], (int, float))]
  average_hallucination = (sum(hallucination_values) / len(hallucination_values)) if hallucination_values else None

  metadata_rows = [[row[0] for row in all_rows]]

  # Import the normalizer from the OOP class
  from summary_calculator import MetadataNormalizer
  normalizer = MetadataNormalizer()
  normalized_metadata = normalizer.normalize(metadata_rows, 0, SPREADSHEET_PREFIX)

  final_row_index = len(summaries) + 4
  summary_worksheet.cell(final_row_index, 1, normalized_metadata)
  c2 = summary_worksheet.cell(final_row_index, 2, average_wer)
  c3 = summary_worksheet.cell(final_row_index, 3, total_sessions)
  c4 = summary_worksheet.cell(final_row_index, 4, average_hallucination)

  for col in (1, 2, 3, 4):
    cell = summary_worksheet.cell(final_row_index, col)
    cell.font = Font(name="Aptos", size=9)
    cell.fill = PatternFill("solid", fgColor=CALL_LEVEL_BKGND_COLOR)

  c2.number_format = "0.000"
  c4.number_format = "0.000"

# === workbook_processor.py ===

# workbook_processor.py

from __future__ import annotations
import os
from typing import Optional
from openpyxl import load_workbook, Workbook
from worksheet_reader import WorksheetReader
from metrics_calculator import MetricsCalculator
from session_processor import SessionProcessor, SpeakerSessionProcessor
from worksheet_writer import MetricsWorksheetWriter
from constants import WORKSHEET_PREFIX, METRICS_WORKSHEET_NAME
from styling import style_copied_input_worksheet

class WorkbookProcessor:
  def __init__(self):
    self.metrics_calculator = MetricsCalculator()

  def process_input_workbook(self, input_path: str) -> Optional[str]:
    worksheet_name = self._find_worksheet_name(input_path)
    if not worksheet_name:
      return None

    input_workbook = load_workbook(input_path, read_only=True, data_only=True, keep_links=False)

    try:
      input_worksheet = input_workbook[worksheet_name]
      reader = WorksheetReader(input_worksheet)

      output_path = self._get_output_path(input_path)
      if os.path.exists(output_path):
        os.remove(output_path)

      output_workbook = Workbook()
      self._copy_input_worksheet(output_workbook, input_worksheet, worksheet_name)

      metadata = os.path.basename(input_path).rsplit(".", 1)[0]
      self._generate_metrics(output_workbook, reader, metadata)

      from weekly_summary import add_weekly_summary_sheet, write_weekly_summary
      from overall_summary import add_overall_summary_sheet

      metrics_ws = output_workbook[METRICS_WORKSHEET_NAME]
      weekly_ws = add_weekly_summary_sheet(output_workbook)
      write_weekly_summary(metrics_ws, weekly_ws)
      add_overall_summary_sheet(output_workbook, metrics_ws)

      output_workbook.save(output_path)
      return output_path

    finally:
      input_workbook.close()

  def _find_worksheet_name(self, input_path: str) -> Optional[str]:
    try:
      workbook = load_workbook(input_path, read_only=True, data_only=True, keep_links=False)
      try:
        return next((n for n in workbook.sheetnames if n.startswith(WORKSHEET_PREFIX)), None)
      finally:
        workbook.close()
    except Exception:
      return None

  def _get_output_path(self, input_path: str) -> str:
    directory = os.path.dirname(input_path)
    base = os.path.basename(input_path).rsplit(".", 1)[0]
    return os.path.join(directory, f"{base}_metrics.xlsx")

  def _copy_input_worksheet(self, output_workbook: Workbook, input_worksheet, worksheet_name: str) -> None:
    copied_worksheet = output_workbook.active
    copied_worksheet.title = worksheet_name

    for row_values in input_worksheet.iter_rows(values_only=True):
      copied_worksheet.append(row_values)

    style_copied_input_worksheet(copied_worksheet)

  def _generate_metrics(self, workbook: Workbook, reader: WorksheetReader, metadata: str) -> None:
    writer = MetricsWorksheetWriter(workbook)
    writer.create_worksheet()

    if reader.has_vtype_column():
      self._process_speaker_sessions(reader, writer, metadata)
    else:
      self._process_regular_sessions(reader, writer, metadata)

    writer.apply_styling()

  def _process_regular_sessions(self, reader: WorksheetReader, writer: MetricsWorksheetWriter, metadata: str) -> None:
    sessions = reader.read_sessions()
    processor = SessionProcessor(reader, self.metrics_calculator)

    for session in sessions.values():
      metrics_list = processor.process_session(session, metadata)
      for metrics in metrics_list:
        writer.write_metrics_row(metrics)

  def _process_speaker_sessions(self, reader: WorksheetReader, writer: MetricsWorksheetWriter, metadata: str) -> None:
    sessions = reader.read_speaker_sessions()
    processor = SpeakerSessionProcessor(reader, self.metrics_calculator)

    for session in sessions.values():
      metrics_list = processor.process_speaker_session(session, metadata)
      for metrics in metrics_list:
        writer.write_metrics_row(metrics)

# === worksheet_reader.py ===

# worksheet_reader.py

from __future__ import annotations
from typing import Optional
from openpyxl.worksheet.worksheet import Worksheet
from data_models import TranscriptPair, SessionData, SpeakerSessionData, HallucinationData
from constants import (
  SESSION_ID_COL_NAME,
  RAW_TRANSCRIPT_COL_NAME,
  GROUND_TRUTH_COL_NAME,
  HALLUCINATION_COL_NAME,
  VTYPE_COL_NAME,
  CUSTOMER_VALUE,
  AGENT_VALUE,
  USE_HALLUCINATION_FLAGS,
)

class WorksheetReader:
  def __init__(self, worksheet: Worksheet):
    self.worksheet = worksheet
    self.header_map = self._build_header_map()

  def _build_header_map(self) -> dict[str, int]:
    return {cell.value: idx for idx, cell in enumerate(self.worksheet[1], start=1)}

  def has_column(self, column_name: str) -> bool:
    return column_name in self.header_map

  def has_vtype_column(self) -> bool:
    return self.has_column(VTYPE_COL_NAME)

  def read_sessions(self) -> dict[str, SessionData]:
    session_id_index = self.header_map[SESSION_ID_COL_NAME] - 1
    raw_transcript_index = self.header_map[RAW_TRANSCRIPT_COL_NAME] - 1
    ground_truth_index = self.header_map[GROUND_TRUTH_COL_NAME] - 1

    sessions: dict[str, list[TranscriptPair]] = {}

    for row in self.worksheet.iter_rows(min_row=2, values_only=True):
      session_id = str(row[session_id_index] or "").strip()
      if not session_id:
        continue

      pair = TranscriptPair(
        transcript=row[raw_transcript_index],
        ground_truth=row[ground_truth_index]
      )
      sessions.setdefault(session_id, []).append(pair)

    return {
      sid: SessionData(session_id=sid, transcript_pairs=pairs)
      for sid, pairs in sessions.items()
    }

  def read_speaker_sessions(self) -> dict[str, SpeakerSessionData]:
    session_id_index = self.header_map[SESSION_ID_COL_NAME] - 1
    raw_transcript_index = self.header_map[RAW_TRANSCRIPT_COL_NAME] - 1
    ground_truth_index = self.header_map[GROUND_TRUTH_COL_NAME] - 1
    vtype_index = self.header_map[VTYPE_COL_NAME] - 1

    sessions: dict[str, SpeakerSessionData] = {}

    for row in self.worksheet.iter_rows(min_row=2, values_only=True):
      session_id = str(row[session_id_index] or "").strip()
      if not session_id:
        continue

      if session_id not in sessions:
        sessions[session_id] = SpeakerSessionData(session_id=session_id)

      vtype = str(row[vtype_index] or "").strip()
      pair = TranscriptPair(
        transcript=row[raw_transcript_index],
        ground_truth=row[ground_truth_index]
      )

      if vtype == CUSTOMER_VALUE:
        sessions[session_id].customer_pairs.append(pair)
      elif vtype == AGENT_VALUE:
        sessions[session_id].agent_pairs.append(pair)

    return sessions

  def read_hallucination_data(self, session_id: str, vtype: Optional[str] = None) -> HallucinationData:
    session_id_index = self.header_map[SESSION_ID_COL_NAME] - 1
    hallucination_index = self.header_map[HALLUCINATION_COL_NAME] - 1
    vtype_index = self.header_map.get(VTYPE_COL_NAME, 0) - 1 if vtype else None

    counts: list[int] = []
    texts: list[str] = []

    for row in self.worksheet.iter_rows(min_row=2, values_only=True):
      if len(row) <= max(session_id_index, hallucination_index):
        continue

      row_session_id = str(row[session_id_index] or "").strip()
      if row_session_id != session_id:
        continue

      if vtype and vtype_index is not None:
        if len(row) <= vtype_index:
          continue
        row_vtype = str(row[vtype_index] or "").strip()
        if row_vtype != vtype:
          continue

      hallucination = row[hallucination_index]
      hallucination_text = str(hallucination).strip() if hallucination else ""
      texts.append(hallucination_text)

      if not hallucination:
        counts.append(0)
      elif USE_HALLUCINATION_FLAGS:
        counts.append(1)
      else:
        counts.append(len(hallucination_text.split()))

    return HallucinationData(counts=counts, texts=texts)

# === worksheet_writer.py ===

# worksheet_writer.py

from __future__ import annotations
from typing import Optional
from openpyxl import Workbook
from openpyxl.worksheet.worksheet import Worksheet
from openpyxl.styles import Font, Alignment, PatternFill
from data_models import MetricsRow, SummaryData
from styling import THIN_BORDER
from constants import (
  METRICS_WORKSHEET_NAME,
  METADATA_COL_NAME,
  SESSION_ID_COL_NAME,
  SECTION_COL_NAME,
  GT_SECTION_TEXT_COL_NAME,
  MODEL_SECTION_TEXT_COL_NAME,
  WER_COL_NAME,
  HALLUCINATION_COUNT_COL_NAME,
  GT_TOKS_COL_NAME,
  HALLUCINATION_PERCENT_COL_NAME,
  HALLUCINATION_COL_NAME,
  CALL_LEVEL_BKGND_COLOR,
  SAMPLE_LEVEL_BKGND_COLOR,
  AVERAGE_WER_COL_NAME,
  SESSION_COUNT_COL_NAME,
  AVG_HALLUCINATION_PERCENT_COL_NAME,
  CALL_LEVEL_GRANULARITY,
)

class MetricsWorksheetWriter:
  def __init__(self, workbook: Workbook):
    self.workbook = workbook
    self.worksheet: Optional[Worksheet] = None

  def create_worksheet(self) -> Worksheet:
    if METRICS_WORKSHEET_NAME in self.workbook.sheetnames:
      del self.workbook[METRICS_WORKSHEET_NAME]
    self.worksheet = self.workbook.create_sheet(METRICS_WORKSHEET_NAME)
    self._write_header()
    return self.worksheet

  def _write_header(self) -> None:
    headers = [
      METADATA_COL_NAME,
      SESSION_ID_COL_NAME,
      SECTION_COL_NAME,
      GT_SECTION_TEXT_COL_NAME,
      MODEL_SECTION_TEXT_COL_NAME,
      WER_COL_NAME,
      HALLUCINATION_COUNT_COL_NAME,
      GT_TOKS_COL_NAME,
      HALLUCINATION_PERCENT_COL_NAME,
      HALLUCINATION_COL_NAME,
    ]

    for col_index, title in enumerate(headers, start=1):
      cell = self.worksheet.cell(1, col_index, title)
      cell.font = Font(name="Aptos", size=9, bold=True)
      cell.alignment = Alignment("left", "center")

    self.worksheet.freeze_panes = "A2"

  def write_metrics_row(self, metrics: MetricsRow) -> None:
    row_index = self.worksheet.max_row + 1
    font = Font(name="Aptos", size=9)
    alignment = Alignment("left", "center")
    fill_color = CALL_LEVEL_BKGND_COLOR if metrics.is_entire else SAMPLE_LEVEL_BKGND_COLOR
    fill = PatternFill("solid", fgColor=fill_color)

    values = [
      metrics.metadata,
      metrics.session_id,
      metrics.section,
      metrics.ground_truth_text,
      metrics.model_text,
      metrics.wer,
      metrics.hallucination_count,
      metrics.ground_truth_tokens,
      metrics.hallucination_percent,
      metrics.hallucination_text,
    ]

    for col_index, value in enumerate(values, start=1):
      cell = self.worksheet.cell(row_index, col_index, value)
      cell.font = font
      cell.alignment = alignment
      cell.fill = fill
      cell.border = THIN_BORDER

      header_value = self.worksheet.cell(1, col_index).value
      if header_value == WER_COL_NAME:
        cell.number_format = "0.0000"
      elif header_value == HALLUCINATION_PERCENT_COL_NAME:
        cell.number_format = "0.0000"

  def apply_styling(self) -> None:
    from styling import style_metrics_columns
    style_metrics_columns(self.worksheet)

class SummaryWorksheetWriter:
  def __init__(self, workbook: Workbook, worksheet_name: str):
    self.workbook = workbook
    self.worksheet_name = worksheet_name
    self.worksheet: Optional[Worksheet] = None

  def create_worksheet(self, has_speaker_column: bool = False) -> Worksheet:
    if self.worksheet_name in self.workbook.sheetnames:
      del self.workbook[self.worksheet_name]
    self.worksheet = self.workbook.create_sheet(self.worksheet_name)
    self._write_header(has_speaker_column)
    return self.worksheet

  def _write_header(self, has_speaker_column: bool) -> None:
    headers = [METADATA_COL_NAME]
    if has_speaker_column:
      headers.append("Speaker")
    headers.extend([
      AVERAGE_WER_COL_NAME,
      SESSION_COUNT_COL_NAME,
      AVG_HALLUCINATION_PERCENT_COL_NAME
    ])

    for col, title in enumerate(headers, start=1):
      cell = self.worksheet.cell(1, col, title)
      cell.font = Font(name="Aptos", size=9, bold=True)
      cell.alignment = Alignment("left", "center")

  def write_summary_row(self, summary: SummaryData, row_num: int, has_speaker_column: bool) -> None:
    values = [summary.metadata]
    if has_speaker_column:
      values.append(summary.speaker)
    values.extend([
      summary.average_wer,
      summary.session_count,
      summary.average_hallucination_percent
    ])

    for col, value in enumerate(values, start=1):
      cell = self.worksheet.cell(row_num, col, value)
      cell.font = Font(name="Aptos", size=9)
      cell.alignment = Alignment("left", "center")
      cell.fill = PatternFill(
        "solid",
        fgColor=CALL_LEVEL_BKGND_COLOR if CALL_LEVEL_GRANULARITY else SAMPLE_LEVEL_BKGND_COLOR
      )
      cell.border = THIN_BORDER

      wer_col = 3 if has_speaker_column else 2
      halluc_col = 5 if has_speaker_column else 4

      if col == wer_col or col == halluc_col:
        cell.number_format = "0.0000"

# =========== plant uml ===============
@startuml ASR Metrics Processing

skinparam BoxPadding 10
skinparam ParticipantPadding 20
skinparam BoxBackgroundColor #F5F5F5

actor User

box "Orchestration" #F5F5F5
    participant Orchestrator
end box

box "File Management" #F5F5F5
    participant FileManager
end box

box "Weekly Processing" #F5F5F5
    participant WorkbookProcessor
    participant WorksheetReader
    participant SessionProcessor
    participant MetricsCalculator
    participant MetricsWriter
end box

box "Monthly Processing" #F5F5F5
    participant MonthlyProcessor
    participant SummaryCalculator
    participant SummaryWriter
end box

== Weekly Processing ==

User -> Orchestrator: run()
activate Orchestrator

Orchestrator -> FileManager: list_input_spreadsheets()
FileManager --> Orchestrator: input_files[]

Orchestrator -> WorkbookProcessor: process_input_workbook()
activate WorkbookProcessor

WorkbookProcessor -> WorksheetReader: read data
activate WorksheetReader
WorksheetReader --> WorkbookProcessor: SessionData
deactivate WorksheetReader

WorkbookProcessor -> SessionProcessor: process_session()
activate SessionProcessor

SessionProcessor -> MetricsCalculator: calculate_metrics()
activate MetricsCalculator
MetricsCalculator --> SessionProcessor: MetricsRow[]
deactivate MetricsCalculator

SessionProcessor --> WorkbookProcessor: metrics[]
deactivate SessionProcessor

WorkbookProcessor -> MetricsWriter: write_metrics()
activate MetricsWriter
MetricsWriter --> WorkbookProcessor: done
deactivate MetricsWriter

WorkbookProcessor --> Orchestrator: weekly_metrics_file
deactivate WorkbookProcessor

== Monthly Consolidation ==

Orchestrator -> MonthlyProcessor: create_monthly_workbook()
activate MonthlyProcessor

MonthlyProcessor -> MonthlyProcessor: consolidate weekly files

MonthlyProcessor -> SummaryCalculator: calculate_summary()
activate SummaryCalculator
SummaryCalculator --> MonthlyProcessor: SummaryData[]
deactivate SummaryCalculator

MonthlyProcessor -> SummaryWriter: write_summary()
activate SummaryWriter
SummaryWriter --> MonthlyProcessor: done
deactivate SummaryWriter

MonthlyProcessor --> Orchestrator: monthly_file
deactivate MonthlyProcessor

Orchestrator --> User: complete
deactivate Orchestrator

@enduml