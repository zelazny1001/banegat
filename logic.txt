# standalone_asr_metrics_baseline.py
# ingest all ASR_*.xlsx spreadsheets in ROOT_DIR and write per-file metrics & a consolidated monthly report

from __future__ import annotations
from typing import Tuple
import os
import re
import requests
import random

from openpyxl import load_workbook, Workbook
from openpyxl.worksheet.worksheet import Worksheet
from openpyxl.styles import Font, Alignment, PatternFill
from openpyxl.utils import get_column_letter
from openpyxl.styles import Border, Side

THIN_SIDE   = Side(border_style="thin", color="D3D3D3")
THIN_BORDER = Border(top=THIN_SIDE, bottom=THIN_SIDE, left=THIN_SIDE, right=THIN_SIDE)
METRICS_COL_WIDTHS = {"A": 30, "B": 13, "C": 16, "D": 22}

CODE_IS_BEING_TESTED: bool = True
CALL_LEVEL_BKGND_COLOR   = "00FFFF"
SAMPLE_LEVEL_BKGND_COLOR = "FFFFFF" # "CFE8D7"
ROOT_DIR: str = "j:/projects/sheet-logic/asr-april-2025-data/" #"j:/projects/sheet-logic/asr-april-2025-data-agent-cust/"
SPREADSHEET_PREFIX: str = "ASR"
WORKSHEET_PREFIX: str = "ASR"
DO_MONTHLY_CONSOLIDATION = True
CALL_LEVEL_GRANULARITY: bool = True

SESSION_ID_COL_NAME: str         = "session_id"
RAW_TRANSCRIPT_COL_NAME: str     = "raw_transcript"
GROUND_TRUTH_COL_NAME: str       = "Ground Truth Transcript"
HALLUCINATION_COL_NAME: str      = "Hallucination"

METRICS_WORKSHEET_NAME: str             = "metrics"
METADATA_COL_NAME: str                  = "metadata"
SECTION_COL_NAME                        = "section"
ENTIRE_COL_NAME: str                    = "entire"
GT_SECTION_TEXT_COL_NAME: str           = "gt section"
MODEL_SECTION_TEXT_COL_NAME: str        = "model text"
WER_COL_NAME                            = "WER"
HALLUCINATION_COUNT_COL_NAME: str       = "Hallucination"
GT_TOKS_COL_NAME: str                   = "GT Toks"
HALLUCINATION_PERCENT_COL_NAME: str     = "Hallucination %"

NUMBER_OF_SECTIONS: int          = 5
WER_POST_ENDPOINT: str           = "https://wer_host:3281/word_error_rate"

WEEKLY_SUMMARY_WORKSHEET_NAME: str        = "summary"
AVERAGE_WER_COL_NAME: str                 = "AVG_WER"
SESSION_COUNT_COL_NAME: str               = "num sessions"
SUMMARY_HALLUCINATION_COUNT_COL_NAME: str = "Hallucination Count"
HALLUCINATION_AVG_COL_NAME:   str         = "Hallucination Avg"

SAMPLE_SUMMARY_WORKSHEET_NAME: str        = "Sample Summary"
AVG_HALLUCINATION_PERCENT_COL_NAME: str   = "Avg Hallucination %"

def get_column_index_map(ws: Worksheet) -> dict[str, int]:
    return {c.value: idx for idx, c in enumerate(ws[1], start=1)}

def debug_print_column_map(ws: Worksheet) -> None:
  hdr_map = get_column_index_map(ws)
  print("Column name -> Excel index -> tuple index")
  for name, excel_idx in hdr_map.items():
    tuple_idx = excel_idx - 1
    col_letter = get_column_letter(excel_idx)
    print(f"{name:30s}  {excel_idx:2d} ({col_letter})  tuple[{tuple_idx}]")

def style_summary_worksheet(ws):
  """
  Apply consistent styling to summary or sample summary sheets:
  - Freeze header
  - Set column widths
  - Apply header font/alignment (row 1)
  - Apply data row style and fill (row 2)
  """
  ws.freeze_panes = "A2"
  ws.auto_filter.ref = f"A1:{get_column_letter(ws.max_column)}{ws.max_row}"

  # Header (row 1)
  for cell in ws[1]:
    cell.font = Font(name="Aptos", size=9, bold=True)
    cell.alignment = Alignment("left", "center")

  # Data row (row 2)
  fill_color = CALL_LEVEL_BKGND_COLOR if CALL_LEVEL_GRANULARITY else SAMPLE_LEVEL_BKGND_COLOR
  for cell in ws[2]:
    cell.font = Font(name="Aptos", size=9)
    cell.alignment = Alignment("left", "center")
    cell.fill = PatternFill("solid", fgColor=fill_color)
    cell.border = THIN_BORDER

  # Set column widths
  for col_letter, width in METRICS_COL_WIDTHS.items():
    ws.column_dimensions[col_letter].width = width

def list_input_spreadsheets(root_dir: str) -> list[str]:
    return sorted(
        os.path.join(root_dir, f)
        for f in os.listdir(root_dir)
        if (
            f.startswith(f"{SPREADSHEET_PREFIX}_")
            and f.lower().endswith(".xlsx")
            and not f.endswith("_metrics.xlsx")
            and not f.endswith("_monthly_metrics.xlsx")
        )
    )

def get_name_of_results_spreadsheet(input_path: str) -> str:
    dir_name = os.path.dirname(input_path)
    base = os.path.basename(input_path).rsplit(".", 1)[0]
    return os.path.join(dir_name, f"{base}_metrics.xlsx")

def preprocess_text(text: str) -> str:
    if not text:
        return ""
    s = str(text).lower()
    s = re.sub(r"[.,\-?…]", " ", s)
    s = re.sub(r"\{[^}]*\}", "", s)
    s = re.sub(r"[\[\]]", "", s)
    return re.sub(r"\s+", " ", s).strip()

def get_wer_from_api(endpoint: str, ground_truth: str, transcript: str) -> Tuple[float, int]:
    if CODE_IS_BEING_TESTED:
        return round(random.uniform(0, 100), 4), random.randint(15, 300)
    try:
        resp = requests.post(
            endpoint,
            json={"groundTruth": ground_truth, "transcript": transcript},
            verify=False,
            timeout=10
        )
        data = resp.json()
        return round(float(data[0]), 4), int(data[1])
    except Exception:
        return float('nan'), None

def add_metrics_sheet(wb: Workbook) -> Worksheet:
    if METRICS_WORKSHEET_NAME in wb.sheetnames:
        del wb[METRICS_WORKSHEET_NAME]
    return wb.create_sheet(METRICS_WORKSHEET_NAME)

def write_header(ws: Worksheet) -> None:
    headers = [
        METADATA_COL_NAME,
        SESSION_ID_COL_NAME,
        SECTION_COL_NAME,
        GT_SECTION_TEXT_COL_NAME,
        MODEL_SECTION_TEXT_COL_NAME,
        WER_COL_NAME,
        HALLUCINATION_COUNT_COL_NAME,
        GT_TOKS_COL_NAME,
        HALLUCINATION_PERCENT_COL_NAME
    ]
    for idx, title in enumerate(headers, start=1):
        cell = ws.cell(row=1, column=idx, value=title)
        cell.font = Font(name="Aptos", size=9, bold=True)
        cell.alignment = Alignment("left", "center")
    ws.freeze_panes = "A2"

def write_metrics_row(
    ws: Worksheet,
    metadata: str,
    session_id: str,
    section,
    gt_text: str,
    model_text: str,
    wer: float,
    hallucination_count: int,
    gt_tok_count: int,
    hallucination_percent: float,
    is_entire: bool = False
) -> int:
    row = ws.max_row + 1
    body_font  = Font(name="Aptos", size=9)
    body_align = Alignment("left", "center")
    fill = PatternFill("solid", fgColor=CALL_LEVEL_BKGND_COLOR if is_entire else SAMPLE_LEVEL_BKGND_COLOR)

    vals = (metadata, session_id, section, gt_text, model_text, wer,
            hallucination_count, gt_tok_count, hallucination_percent)
    for col_idx, v in enumerate(vals, start=1):
        cell = ws.cell(row=row, column=col_idx, value=v)
        cell.font = body_font
        cell.alignment = body_align
        cell.fill = fill
        cell.border = THIN_BORDER
        if ws.cell(1, col_idx).value == WER_COL_NAME:
            cell.number_format = "0.00"
        if ws.cell(1, col_idx).value == HALLUCINATION_PERCENT_COL_NAME:
            cell.number_format = "0.00000"
    return row

def process_sessions(input_ws: Worksheet, metrics_ws: Worksheet, metadata: str) -> None:
    hdr_map = get_column_index_map(input_ws)
    sid_idx = hdr_map[SESSION_ID_COL_NAME] - 1
    raw_idx = hdr_map[RAW_TRANSCRIPT_COL_NAME] - 1
    gt_idx  = hdr_map[GROUND_TRUTH_COL_NAME] - 1

    data = [
        row for row in input_ws.iter_rows(min_row=2, values_only=True)
        if str(row[sid_idx] or "").strip()
    ]
    if not data:
        print(f"No session_id found – skipping process_sessions for {metadata}")
        return

    sessions: dict[str, list[tuple[str, str]]] = {}
    for row in data:
        sid = str(row[sid_idx]).strip()
        sessions.setdefault(sid, []).append((row[raw_idx], row[gt_idx]))

    for sid, entries in sessions.items():
        hallucination_flags = get_hallucination_flags(input_ws, sid)
        gt_all  = " ".join(preprocess_text(gt) for _, gt in entries)
        raw_all = " ".join(preprocess_text(raw) for raw, _ in entries)
        wer_ent, gt_tok_count = get_wer_from_api(WER_POST_ENDPOINT, gt_all, raw_all)
        hallucination_count = sum(hallucination_flags)
        hallucination_percent = (100 * hallucination_count / gt_tok_count) if gt_tok_count else None
        write_metrics_row(metrics_ws, metadata, sid, ENTIRE_COL_NAME,
                          gt_all, raw_all, wer_ent, hallucination_count, gt_tok_count, hallucination_percent, True)

        total = len(entries)
        base  = total // NUMBER_OF_SECTIONS
        rem   = total % NUMBER_OF_SECTIONS
        start = 0
        for sec in range(1, NUMBER_OF_SECTIONS + 1):
            cnt = base + (1 if sec <= rem else 0)
            if cnt == 0: break
            block  = entries[start:start+cnt]
            flags  = hallucination_flags[start:start+cnt]
            start += cnt
            gt_blk = " ".join(preprocess_text(gt) for _, gt in block)
            raw_blk= " ".join(preprocess_text(raw) for raw, _ in block)
            wer_s, gt_tok_count = get_wer_from_api(WER_POST_ENDPOINT, gt_blk, raw_blk)
            hallucination_count = sum(flags)
            hallucination_percent = (100 * hallucination_count / gt_tok_count) if gt_tok_count else None
            write_metrics_row(metrics_ws, metadata, sid, sec,
                              gt_blk, raw_blk, wer_s, hallucination_count, gt_tok_count, hallucination_percent)

def get_hallucination_flags(input_ws: Worksheet, sid: str) -> list[int]:
    hdr_map = get_column_index_map(input_ws)
    sid_idx = hdr_map[SESSION_ID_COL_NAME] - 1
    hi = hdr_map.get(HALLUCINATION_COL_NAME)
    if not hi:
        return []
    hi -= 1
    flags = []
    for row in input_ws.iter_rows(min_row=2, values_only=True):
        if str(row[sid_idx]) == sid:
            flags.append(1 if row[hi] else 0)
    return flags

def style_columns(ws: Worksheet) -> None:
    widths = {1:27, 2:65, 3:9, 4:63, 5:63, 6:9, 7:12, 8:10, 9:15}
    for col, w in widths.items():
        ws.column_dimensions[get_column_letter(col)].width = w
    ws.auto_filter.ref = f"A1:I{ws.max_row}"

def calculate_hallucination_stats(metrics_ws: Worksheet) -> tuple[int, float]:
    hdr_map = get_column_index_map(metrics_ws)
    hi = hdr_map[HALLUCINATION_COUNT_COL_NAME] - 1
    si = hdr_map[SECTION_COL_NAME] - 1
    vals = [
        row[hi] for row in metrics_ws.iter_rows(min_row=2, values_only=True)
        if row[si] == ENTIRE_COL_NAME and isinstance(row[hi], (int, float))
    ]
    total = sum(vals); cnt = len(vals)
    return total, (total / cnt if cnt else 0.0)

def calculate_mean_wer(metrics_ws: Worksheet) -> float:
    hdr_map = get_column_index_map(metrics_ws)
    wi = hdr_map[WER_COL_NAME] - 1
    si = hdr_map[SECTION_COL_NAME] - 1
    vals = [
        row[wi] for row in metrics_ws.iter_rows(min_row=2, values_only=True)
        if row[si] == ENTIRE_COL_NAME and isinstance(row[wi], (int, float))
    ]
    return sum(vals) / len(vals) if vals else 0.0

def add_summary_sheet(wb: Workbook) -> Worksheet:
    if WEEKLY_SUMMARY_WORKSHEET_NAME in wb.sheetnames:
        del wb[WEEKLY_SUMMARY_WORKSHEET_NAME]
    return wb.create_sheet(WEEKLY_SUMMARY_WORKSHEET_NAME)

def write_summary(metrics_ws: Worksheet, summary_ws: Worksheet) -> None:
    headers = [
        METADATA_COL_NAME,
        AVERAGE_WER_COL_NAME,
        SESSION_COUNT_COL_NAME,
        SUMMARY_HALLUCINATION_COUNT_COL_NAME,
        HALLUCINATION_AVG_COL_NAME
    ]
    for i, title in enumerate(headers, start=1):
        c = summary_ws.cell(1, i, title)
        c.font = Font(name="Aptos", size=11, bold=True)
        c.alignment = Alignment("left", "center")

    meta = metrics_ws.cell(2, 1).value
    mean = calculate_mean_wer(metrics_ws)
    total_h, avg_h = calculate_hallucination_stats(metrics_ws)
    hdr_map = get_column_index_map(metrics_ws)
    si = hdr_map[SECTION_COL_NAME] - 1
    sessions = sum(1 for r in metrics_ws.iter_rows(min_row=2, values_only=True) if r[si] == ENTIRE_COL_NAME)

    summary_ws.append([meta, mean, sessions, total_h, round(avg_h, 2)])
    summary_ws.cell(2, 2).number_format = "0.00"

    for c in summary_ws[2]:
        c.font = Font(name="Aptos", size=9)
        c.alignment = Alignment("left", "center")

    col_widths = {"A":30, "B":13, "C":16, "D":22, "E":19}
    for col, w in col_widths.items():
        summary_ws.column_dimensions[col].width = w

import re

def get_normalized_metadata(rows, meta_index, prefix):
    metas = [r[meta_index] for r in rows if r[meta_index]]
    parts = [re.search(r'_(\d{4})thru(\d{4})_(\d{4})', m) for m in metas if m]
    earliest = min(p.group(1) for p in parts if p)
    latest = max(p.group(2) for p in parts if p)
    year = parts[0].group(3) if parts else "????"
    return f"{prefix}_{earliest}thru{latest}_{year}"

def add_sample_summary_sheet(wb: Workbook, metrics_ws: Worksheet) -> None:
  if SAMPLE_SUMMARY_WORKSHEET_NAME in wb.sheetnames:
    del wb[SAMPLE_SUMMARY_WORKSHEET_NAME]
  ws = wb.create_sheet(SAMPLE_SUMMARY_WORKSHEET_NAME)
  headers = [
    METADATA_COL_NAME,
    AVERAGE_WER_COL_NAME,
    SESSION_COUNT_COL_NAME,
    AVG_HALLUCINATION_PERCENT_COL_NAME
  ]
  for i, title in enumerate(headers, start=1):
    c = ws.cell(1, i, title)
    c.font = Font(name="Aptos", size=9, bold=True)
    c.alignment = Alignment("left", "center")

  header_map = get_column_index_map(metrics_ws)
  rows = list(metrics_ws.iter_rows(min_row=2, values_only=True))

  wer_index = header_map[WER_COL_NAME] - 1
  hallucination_index = header_map[HALLUCINATION_PERCENT_COL_NAME] - 1
  section_index = header_map[SECTION_COL_NAME] - 1
  meta_index = header_map[METADATA_COL_NAME] - 1

  if CALL_LEVEL_GRANULARITY:
    wer_vals = [r[wer_index] for r in rows if
                r[section_index] == ENTIRE_COL_NAME and isinstance(r[wer_index], (int, float))]
    halluc_vals = [r[hallucination_index] for r in rows if
                   r[section_index] == ENTIRE_COL_NAME and isinstance(r[hallucination_index], (int, float))]
  else:
    wer_vals = [r[wer_index] for r in rows if
                r[section_index] != ENTIRE_COL_NAME and isinstance(r[wer_index], (int, float))]
    halluc_vals = [r[hallucination_index] for r in rows if
                   r[section_index] != ENTIRE_COL_NAME and isinstance(r[hallucination_index], (int, float))]

  avg_wer = sum(wer_vals) / len(wer_vals) if wer_vals else 0.0
  avg_hp = sum(halluc_vals) / len(halluc_vals) if halluc_vals else 0.0

  metas = [r[meta_index] for r in rows if r[meta_index]]
  parts = [re.search(r'_(\d{4})thru(\d{4})_(\d{4})', m) for m in metas if m]
  earliest = min(p.group(1) for p in parts if p)
  latest = max(p.group(2) for p in parts if p)
  year = parts[0].group(3) if parts else "????"
  meta = f"{SPREADSHEET_PREFIX}_{earliest}thru{latest}_{year}"

  num_sessions = sum(1 for r in rows if r[section_index] == ENTIRE_COL_NAME)

  summary_vals = [meta, avg_wer, num_sessions, avg_hp]
  for i, val in enumerate(summary_vals, start=1):
    c = ws.cell(2, i, val)
    c.font = Font(name="Aptos", size=9)
    c.alignment = Alignment("left", "center")
    c.fill = PatternFill(
      "solid",
      fgColor=CALL_LEVEL_BKGND_COLOR if CALL_LEVEL_GRANULARITY else SAMPLE_LEVEL_BKGND_COLOR
    )
    c.border = THIN_BORDER

  col_widths = {"A": 30, "B": 13, "C": 16, "D": 22}
  for col, w in col_widths.items():
    ws.column_dimensions[col].width = w

def OLD_add_sample_summary_sheet(wb: Workbook, metrics_ws: Worksheet) -> None:
    if SAMPLE_SUMMARY_WORKSHEET_NAME in wb.sheetnames:
        del wb[SAMPLE_SUMMARY_WORKSHEET_NAME]
    worksheet = wb.create_sheet(SAMPLE_SUMMARY_WORKSHEET_NAME)
    headers = [
        METADATA_COL_NAME,
        AVERAGE_WER_COL_NAME,
        SESSION_COUNT_COL_NAME,
        AVG_HALLUCINATION_PERCENT_COL_NAME
    ]
    for i, title in enumerate(headers, start=1):
        c = worksheet.cell(1, i, title)
        c.font = Font(name="Aptos", size=9, bold=True)
        c.alignment = Alignment("left", "center")

    # worksheet.append([None] * len(headers)) # use to append a blank row after the header if required

    rows = list(metrics_ws.iter_rows(min_row=1, values_only=True))
    header_map = get_column_index_map(metrics_ws)
    wer_index = header_map[WER_COL_NAME] - 1
    hallucination_index = header_map[HALLUCINATION_PERCENT_COL_NAME] - 1
    section_index = header_map[SECTION_COL_NAME] - 1
    if CALL_LEVEL_GRANULARITY:
        wer_vals = [row[wer_index] for row in rows if row[section_index] == ENTIRE_COL_NAME and isinstance(row[wer_index], (int, float))]
        hallucination_vals  = [row[hallucination_index] for row in rows if row[section_index] == ENTIRE_COL_NAME and isinstance(row[hallucination_index], (int, float))]
    else:
        wer_vals = [r[wer_index] for r in rows if r[section_index] != ENTIRE_COL_NAME and isinstance(r[wer_index], (int, float))]
        hallucination_vals  = [r[hallucination_index] for r in rows if r[section_index] != ENTIRE_COL_NAME and isinstance(r[hallucination_index], (int, float))]
    avg_wer = sum(wer_vals) / len(wer_vals) if wer_vals else 0.0
    avg_hp  = sum(hallucination_vals) / len(hallucination_vals) if hallucination_vals else 0.0

    meta = metrics_ws.cell(2, 1).value
    sess_idx = header_map[SESSION_ID_COL_NAME] - 1
    sessions = len(set(r[sess_idx] for r in rows if r[section_index] == ENTIRE_COL_NAME))

    worksheet.append([meta, avg_wer, sessions, avg_hp])
    worksheet.cell(2, 2).number_format = "0.00"
    worksheet.cell(2, 4).number_format = "0.00000"
    for c in worksheet[2]: # row 2 - the summary data row
        c.font = Font(name="Aptos", size=9)
        c.alignment = Alignment("left", "center")
        c.fill = PatternFill("solid", fgColor=CALL_LEVEL_BKGND_COLOR if CALL_LEVEL_GRANULARITY else SAMPLE_LEVEL_BKGND_COLOR)
        c.border = THIN_BORDER
    col_widths = {"A":30, "B":13, "C":16, "D":22}
    for col, w in col_widths.items():
        worksheet.column_dimensions[col].width = w

def get_monthly_filepath(root_dir: str, metrics_files: list[str], prefix: str) -> tuple[str, str, str, str]:
    dates = []
    for path in metrics_files:
        base = os.path.basename(path).rsplit(".", 1)[0]
        parts = base.split("_")
        rng, year = parts[1], parts[2]
        start, end = re.split(r'thru|-', rng, maxsplit=1)
        dates.append((start, end, year))
    earliest = min(d[0] for d in dates)
    latest   = max(d[1] for d in dates)
    year     = dates[0][2]
    filename = f"{prefix}_{earliest}thru{latest}_{year}_monthly_metrics.xlsx"
    return os.path.join(root_dir, filename), earliest, latest, year

def create_monthly_worksheet(root_dir: str, metrics_files: list[str], prefix: str) -> str:
    monthly_path, earliest, latest, year = get_monthly_filepath(root_dir, metrics_files, prefix)
    if os.path.exists(monthly_path):
        os.remove(monthly_path)

    wb = Workbook()
    del wb[wb.sheetnames[0]]

    monthly_metrics = wb.create_sheet(METRICS_WORKSHEET_NAME)
    first = True
    for mf in metrics_files:
        wbf = load_workbook(mf)
        wsf = wbf[METRICS_WORKSHEET_NAME]
        for i, row in enumerate(wsf.iter_rows(values_only=True), start=1):
            if i == 1 and not first: continue
            monthly_metrics.append(row)
        first = False

    for c in monthly_metrics[1]:
        c.font = Font(name="Aptos", size=9, bold=True)
        c.alignment = Alignment("left", "center")
    monthly_metrics.freeze_panes = "A2"
    monthly_metrics.auto_filter.ref = f"A1:{get_column_letter(monthly_metrics.max_column)}{monthly_metrics.max_row}"
    for col, w in {"A":27, "B":65, "C":9, "D":63, "E":63, "F":8, "G":12, "H":10, "I":15}.items():
        monthly_metrics.column_dimensions[col].width = w
    hdr_map = get_column_index_map(monthly_metrics)
    wi = hdr_map[WER_COL_NAME] - 1
    hi = hdr_map[HALLUCINATION_PERCENT_COL_NAME] - 1
    si = hdr_map[SECTION_COL_NAME] - 1
    for r in monthly_metrics.iter_rows(min_row=2):
        if r[wi].value is not None:
            r[wi].number_format = "0.00"
        if r[hi].value is not None:
            r[hi].number_format = "0.00000"
        if r[si].value == ENTIRE_COL_NAME:
            for c in r: c.fill, c.border = PatternFill("solid", fgColor=CALL_LEVEL_BKGND_COLOR), THIN_BORDER
        else:
            for c in r: c.fill, c.border = PatternFill("solid", fgColor=SAMPLE_LEVEL_BKGND_COLOR), THIN_BORDER

    mon_sum = wb.create_sheet(WEEKLY_SUMMARY_WORKSHEET_NAME)
    first = True
    for mf in metrics_files:
        wbf = load_workbook(mf)
        wsf = wbf[WEEKLY_SUMMARY_WORKSHEET_NAME]
        for i, row in enumerate(wsf.iter_rows(values_only=True), start=1):
            if i == 1 and not first: continue
            mon_sum.append(row)
        first = False

    for c in mon_sum[1]:
        c.font = Font(name="Aptos", size=9, bold=True)
        c.alignment = Alignment("left", "center")
    mon_sum.freeze_panes = "A2"
    mon_sum.auto_filter.ref = f"A1:{get_column_letter(mon_sum.max_column)}{mon_sum.max_row}"
    for col, w in {"A":36, "B":11, "C":14, "D":19, "E":17}.items():
        mon_sum.column_dimensions[col].width = w

    mon_sum.append([None] * 5)
    entries = list(mon_sum.iter_rows(min_row=2, max_row=1+len(metrics_files), values_only=True))
    avg_wers = [r[1] for r in entries]
    num_sess = sum(int(r[2]) for r in entries)
    total_h  = sum(int(r[3]) for r in entries)
    avg_h    = round(total_h / num_sess, 2) if num_sess else 0.0

    meta_lbl = f"{prefix}_{earliest}thru{latest}_{year}"
    mon_sum.append([meta_lbl,
                    round(sum(avg_wers) / len(avg_wers), 2) if avg_wers else 0.0,
                    num_sess, total_h, avg_h])

    last = mon_sum.max_row
    fill_con = PatternFill("solid", fgColor="00FFFF")
    for row in mon_sum.iter_rows(min_row=1, max_row=last):
        for c in row:
            c.font = Font(name="Aptos", size=9, bold=(c.row == 1))
            if c.row == last:
                c.fill = fill_con
                c.border = THIN_BORDER

    add_sample_summary_sheet(wb, monthly_metrics)
    wb.save(monthly_path)
    return monthly_path

def main() -> None:
    input_files = list_input_spreadsheets(ROOT_DIR)
    metrics_files: list[str] = []

    for inp in input_files:
        wb_in = load_workbook(inp)
        ws_name = next(n for n in wb_in.sheetnames if n.startswith(WORKSHEET_PREFIX))
        in_ws = wb_in[ws_name]

        out_path = get_name_of_results_spreadsheet(inp)
        if os.path.exists(out_path): os.remove(out_path)

        wb_out = Workbook()
        copy_ws = wb_out.active
        copy_ws.title = ws_name
        for row in in_ws.iter_rows(values_only=True): copy_ws.append(row)

        copy_ws.column_dimensions['A'].width = 69
        copy_ws.column_dimensions['B'].width = 35
        copy_ws.column_dimensions['C'].width = 35
        copy_ws.column_dimensions['D'].width = 12
        copy_ws.freeze_panes = "A2"
        copy_ws.auto_filter.ref = f"A1:D{copy_ws.max_row}"
        for row in copy_ws.iter_rows(min_row=1, max_row=copy_ws.max_row, min_col=1, max_col=4):
            for cell in row:
                cell.font = Font(name="Aptos", size=9, bold=(cell.row == 1))

        monthly_worksheet = add_metrics_sheet(wb_out)
        write_header(monthly_worksheet)
        metadata = os.path.basename(inp).rsplit(".", 1)[0]
        process_sessions(in_ws, monthly_worksheet, metadata)

        style_columns(monthly_worksheet)
        summary_worksheet = add_summary_sheet(wb_out)
        write_summary(monthly_worksheet, summary_worksheet)
        add_sample_summary_sheet(wb_out, monthly_worksheet)

        wb_out.save(out_path)
        metrics_files.append(out_path)
        print(f"{len(metrics_files)}/{len(input_files)} ... Saved metrics & summary to {out_path}")

    if DO_MONTHLY_CONSOLIDATION and metrics_files:
        monthly_path = create_monthly_worksheet(ROOT_DIR, metrics_files, SPREADSHEET_PREFIX)
        print(f"Saved monthly consolidated metrics to {monthly_path}")

if __name__ == "__main__":
    main()
	
######################### =======================================

# standalone_asr_interleaved_metrics.py
# extends standalone_asr_metrics_baseline.py to add interleaved metrics when vtype column is present

import os
import re
from collections import defaultdict
from openpyxl import load_workbook, Workbook
from openpyxl.styles import Font, Alignment, PatternFill
from openpyxl.utils import get_column_letter

import standalone_asr_metrics_baseline

# baseline constants
INTERLEAVED_ROOT_DIR = "j:/projects/sheet-logic/asr-april-2025-data-agent-cust/" # standalone_asr_metrics_baseline.ROOT_DIR
INTERLEAVED_SPREADSHEET_PREFIX = standalone_asr_metrics_baseline.SPREADSHEET_PREFIX
INTERLEAVED_WORKSHEET_PREFIX = standalone_asr_metrics_baseline.WORKSHEET_PREFIX
INTERLEAVED_DO_MONTHLY_CONSOLIDATION = standalone_asr_metrics_baseline.DO_MONTHLY_CONSOLIDATION
INTERLEAVED_NUMBER_OF_SECTIONS = standalone_asr_metrics_baseline.NUMBER_OF_SECTIONS
INTERLEAVED_WER_POST_ENDPOINT = standalone_asr_metrics_baseline.WER_POST_ENDPOINT

INTERLEAVED_SESSION_ID_COL_NAME = standalone_asr_metrics_baseline.SESSION_ID_COL_NAME
INTERLEAVED_RAW_TRANSCRIPT_COL_NAME = standalone_asr_metrics_baseline.RAW_TRANSCRIPT_COL_NAME
INTERLEAVED_GROUND_TRUTH_COL_NAME = standalone_asr_metrics_baseline.GROUND_TRUTH_COL_NAME

INTERLEAVED_METADATA_COL_NAME = standalone_asr_metrics_baseline.METADATA_COL_NAME
INTERLEAVED_SECTION_COL_NAME = standalone_asr_metrics_baseline.SECTION_COL_NAME
INTERLEAVED_WER_COL_NAME = standalone_asr_metrics_baseline.WER_COL_NAME
INTERLEAVED_HALLUCINATION_PERCENT_COL_NAME = standalone_asr_metrics_baseline.HALLUCINATION_PERCENT_COL_NAME

INTERLEAVED_THIN_BORDER = standalone_asr_metrics_baseline.THIN_BORDER

# interleaved worksheets
INTERLEAVED_METRICS = "interleaved metrics"
INTERLEAVED_SUMMARY = "interleaved summary"
INTERLEAVED_SAMPLE_SUMMARY = "interleaved sample summary"

# new input column
VTYPE_COL_NAME = "vtype"

def add_named_sheet(wb: Workbook, name: str):
  if name in wb.sheetnames:
    del wb[name]
  return wb.create_sheet(name)

def pick_input_worksheet(wb_in: Workbook) -> str:
  for name in wb_in.sheetnames:
    if name.startswith(INTERLEAVED_WORKSHEET_PREFIX):
      return name
  for name in wb_in.sheetnames:
    if not any(name.lower().startswith(x) for x in [
      "metrics", "summary", "sample summary", "interleaved"
    ]):
      return name
  return wb_in.sheetnames[0]

def has_required_columns(ws) -> bool:
  hdr = [str(c.value).strip().lower() for c in ws[1] if c.value]
  return "session_id" in hdr and "raw_transcript" in hdr

def has_vtype_column(ws) -> bool:
  hdr = [str(c.value).strip().lower() for c in ws[1] if c.value]
  return "vtype" in hdr

def process_interleaved_sessions(input_ws, metrics_ws, metadata: str) -> None:
  hdr = standalone_asr_metrics_baseline.get_column_index_map(input_ws)
  sid_i = hdr[INTERLEAVED_SESSION_ID_COL_NAME] - 1
  raw_i = hdr[INTERLEAVED_RAW_TRANSCRIPT_COL_NAME] - 1
  gt_i = hdr[INTERLEAVED_GROUND_TRUTH_COL_NAME] - 1
  vt_i = hdr.get(VTYPE_COL_NAME, None)
  if vt_i: vt_i -= 1

  data = [
    row for row in input_ws.iter_rows(min_row=2, values_only=True)
    if str(row[sid_i] or "").strip()
  ]
  #print(f"DEBUG: processing {len(data)} rows for interleaved in {metadata}")

  sessions = defaultdict(lambda: defaultdict(list))
  for r in data:
    sid = str(r[sid_i]).strip()
    vtype = str(r[vt_i]).strip() if vt_i is not None and r[vt_i] else "Unknown"
    sessions[sid][vtype].append((r[raw_i], r[gt_i]))

  for sid, roles in sessions.items():
    for role, entries in roles.items():
      gt_all = " ".join(standalone_asr_metrics_baseline.preprocess_text(gt) for _, gt in entries)
      raw_all = " ".join(standalone_asr_metrics_baseline.preprocess_text(raw) for raw, _ in entries)
      wer_ent, tok = standalone_asr_metrics_baseline.get_wer_from_api(INTERLEAVED_WER_POST_ENDPOINT, gt_all, raw_all)
      hall = len(entries)
      hp = (100 * hall / tok) if tok else None
      standalone_asr_metrics_baseline.write_metrics_row(metrics_ws, metadata, sid, role,
                                                        gt_all, raw_all, wer_ent, hall, tok, hp, True)

      total = len(entries)
      base = total // INTERLEAVED_NUMBER_OF_SECTIONS
      rem = total % INTERLEAVED_NUMBER_OF_SECTIONS
      start = 0
      for sec in range(1, INTERLEAVED_NUMBER_OF_SECTIONS + 1):
        cnt = base + (1 if sec <= rem else 0)
        if cnt == 0: break
        block = entries[start:start + cnt]
        start += cnt
        gt_blk = " ".join(standalone_asr_metrics_baseline.preprocess_text(gt) for _, gt in block)
        raw_blk = " ".join(standalone_asr_metrics_baseline.preprocess_text(raw) for raw, _ in block)
        wer_s, tok = standalone_asr_metrics_baseline.get_wer_from_api(INTERLEAVED_WER_POST_ENDPOINT, gt_blk, raw_blk)
        hall = len(block)
        hp = (100 * hall / tok) if tok else None
        standalone_asr_metrics_baseline.write_metrics_row(metrics_ws, metadata, sid, f"{role}_{sec}",
                                                          gt_blk, raw_blk, wer_s, hall, tok, hp)

def OLD_write_interleaved_summary(metrics_ws, summary_ws):
  headers = [
    INTERLEAVED_METADATA_COL_NAME, "AVG_AGENT_WER", "AVG_CUSTOMER_WER",
    "num sessions", "Agent Hallucination Avg", "Customer Hallucination Avg"
  ]
  for i, h in enumerate(headers, start=1):
    c = summary_ws.cell(1, i, h)
    c.font = Font(name="Aptos", size=11, bold=True)
    c.alignment = Alignment("left", "center")

  rows = list(metrics_ws.iter_rows(min_row=2, values_only=True))
  if not rows:
    return
  meta = metrics_ws.cell(2, 1).value

  agent_rows = [r for r in rows if str(r[2]).startswith("Agent")]
  cust_rows = [r for r in rows if str(r[2]).startswith("Customer")]

  def avg(vals):
    return sum(vals) / len(vals) if vals else 0

  avg_awer = avg([r[5] for r in agent_rows if isinstance(r[5], (int, float))])
  avg_cwer = avg([r[5] for r in cust_rows if isinstance(r[5], (int, float))])
  avg_ah = avg([r[8] for r in agent_rows if isinstance(r[8], (int, float))])
  avg_ch = avg([r[8] for r in cust_rows if isinstance(r[8], (int, float))])
  sessions = len(set(r[1] for r in rows))

  summary_ws.append([meta, avg_awer, avg_cwer, sessions, avg_ah, avg_ch])

def OLD_add_interleaved_sample_summary(wb, metrics_ws):
  ws = add_named_sheet(wb, INTERLEAVED_SAMPLE_SUMMARY)
  headers = [
    INTERLEAVED_METADATA_COL_NAME, "AVG_AGENT_WER", "AVG_CUSTOMER_WER",
    "num sessions", "Agent Avg HP", "Customer Avg HP"
  ]
  for i, h in enumerate(headers, start=1):
    c = ws.cell(1, i, h)
    c.font = Font(name="Aptos", size=11, bold=True)
    c.alignment = Alignment("left", "center")

  rows = list(metrics_ws.iter_rows(min_row=2, values_only=True))
  if not rows:
    return
  meta = metrics_ws.cell(2, 1).value

  agent_rows = [r for r in rows if str(r[2]).startswith("Agent_")]
  cust_rows = [r for r in rows if str(r[2]).startswith("Customer_")]

  def avg(vals):
    return sum(vals) / len(vals) if vals else 0

  avg_awer = avg([r[5] for r in agent_rows if isinstance(r[5], (int, float))])
  avg_cwer = avg([r[5] for r in cust_rows if isinstance(r[5], (int, float))])
  avg_ah = avg([r[8] for r in agent_rows if isinstance(r[8], (int, float))])
  avg_ch = avg([r[8] for r in cust_rows if isinstance(r[8], (int, float))])
  sessions = len(set(r[1] for r in rows))

  ws.append([meta, avg_awer, avg_cwer, sessions, avg_ah, avg_ch])

def write_interleaved_summary(metrics_ws, summary_ws):
    headers = [
        INTERLEAVED_METADATA_COL_NAME, "AVG_AGENT_WER", "AVG_CUSTOMER_WER",
        "num sessions", "Avg Agent Hallucination%", "Avg Customer Hallucination%"
    ]
    for i, h in enumerate(headers, start=1):
        c = summary_ws.cell(1, i, h)
        c.font = Font(name="Aptos", size=11, bold=True)
        c.alignment = Alignment("left", "center")

    rows = list(metrics_ws.iter_rows(min_row=2, values_only=True))
    if not rows:
        return

    meta = standalone_asr_metrics_baseline.get_normalized_metadata(rows, 0, INTERLEAVED_SPREADSHEET_PREFIX)

    if standalone_asr_metrics_baseline.CALL_LEVEL_GRANULARITY:
        agent_rows = [r for r in rows if str(r[2]).strip() == "Agent"]
        cust_rows = [r for r in rows if str(r[2]).strip() == "Customer"]
        session_rows = agent_rows + cust_rows
    else:
        agent_rows = [r for r in rows if str(r[2]).startswith("Agent_")]
        cust_rows = [r for r in rows if str(r[2]).startswith("Customer_")]
        session_rows = [r for r in rows if str(r[2]) in ("Agent", "Customer")]

    def avg(vals):
        return sum(vals) / len(vals) if vals else 0

    avg_awer = avg([r[5] for r in agent_rows if isinstance(r[5], (int, float))])
    avg_cwer = avg([r[5] for r in cust_rows if isinstance(r[5], (int, float))])
    avg_ah = avg([r[8] for r in agent_rows if isinstance(r[8], (int, float))])
    avg_ch = avg([r[8] for r in cust_rows if isinstance(r[8], (int, float))])
    sessions = len(session_rows) // 2

    summary_ws.append([meta, avg_awer, avg_cwer, sessions, avg_ah, avg_ch])

def add_interleaved_sample_summary(wb, metrics_ws):
    ws = add_named_sheet(wb, INTERLEAVED_SAMPLE_SUMMARY)
    headers = [
        INTERLEAVED_METADATA_COL_NAME, "AVG_AGENT_WER", "AVG_CUSTOMER_WER",
        "num sessions", "Avg Agent Hallucination%", "Avg Customer Hallucination%"
    ]
    for i, h in enumerate(headers, start=1):
        c = ws.cell(1, i, h)
        c.font = Font(name="Aptos", size=11, bold=True)
        c.alignment = Alignment("left", "center")

    rows = list(metrics_ws.iter_rows(min_row=2, values_only=True))
    if not rows:
        return

    meta = standalone_asr_metrics_baseline.get_normalized_metadata(rows, 0, INTERLEAVED_SPREADSHEET_PREFIX)

    if standalone_asr_metrics_baseline.CALL_LEVEL_GRANULARITY:
        agent_rows = [r for r in rows if str(r[2]).strip() == "Agent"]
        cust_rows = [r for r in rows if str(r[2]).strip() == "Customer"]
        session_rows = agent_rows + cust_rows
    else:
        agent_rows = [r for r in rows if str(r[2]).startswith("Agent_")]
        cust_rows = [r for r in rows if str(r[2]).startswith("Customer_")]
        session_rows = [r for r in rows if str(r[2]) in ("Agent", "Customer")]

    def avg(vals):
        return sum(vals) / len(vals) if vals else 0

    avg_awer = avg([r[5] for r in agent_rows if isinstance(r[5], (int, float))])
    avg_cwer = avg([r[5] for r in cust_rows if isinstance(r[5], (int, float))])
    avg_ah = avg([r[8] for r in agent_rows if isinstance(r[8], (int, float))])
    avg_ch = avg([r[8] for r in cust_rows if isinstance(r[8], (int, float))])
    sessions = len(session_rows) // 2

    ws.append([meta, avg_awer, avg_cwer, sessions, avg_ah, avg_ch])

    # Apply shared styling
    standalone_asr_metrics_baseline.style_summary_worksheet(ws)

def OLD_create_monthly_interleaved(root_dir: str, metrics_files: list[str], prefix: str) -> str:
  path, earliest, latest, year = standalone_asr_metrics_baseline.get_monthly_filepath(root_dir, metrics_files, prefix)
  out_path = path.replace("_monthly_metrics.xlsx", "_monthly_interleaved.xlsx")
  if os.path.exists(out_path): os.remove(out_path)

  wb = Workbook()
  del wb[wb.sheetnames[0]]

  interleaved_metrics = add_named_sheet(wb, INTERLEAVED_METRICS)
  first = True
  for mf in metrics_files:
    wbf = load_workbook(mf)
    if INTERLEAVED_METRICS not in wbf.sheetnames: continue
    ws = wbf[INTERLEAVED_METRICS]
    for i, row in enumerate(ws.iter_rows(values_only=True), start=1):
      if i == 1 and not first: continue
      interleaved_metrics.append(row)
    first = False

  if interleaved_metrics.max_row > 1:
    isum = add_named_sheet(wb, INTERLEAVED_SUMMARY)
    write_interleaved_summary(interleaved_metrics, isum)
    isum.freeze_panes = "A2"
    isum.auto_filter.ref = f"A1:{get_column_letter(isum.max_column)}{isum.max_row}"
    for col, w in {"A": 30, "B": 14, "C": 17, "D": 16, "E": 22, "F": 22}.items():
      isum.column_dimensions[col].width = w
    last = isum.max_row
    fill_con = PatternFill("solid", fgColor="00FFFF")
    for row in isum.iter_rows(min_row=1, max_row=last):
      for c in row:
        c.font = Font(name="Aptos", size=9, bold=(c.row == 1))
        if c.row == last:
          c.fill = fill_con
          c.border = INTERLEAVED_THIN_BORDER

    add_interleaved_sample_summary(wb, interleaved_metrics)

  wb.save(out_path)
  return out_path

def create_monthly_interleaved(root_dir: str, metrics_files: list[str], prefix: str) -> str:
  path, earliest, latest, year = standalone_asr_metrics_baseline.get_monthly_filepath(root_dir, metrics_files, prefix)
  out_path = path.replace("_monthly_metrics.xlsx", "_monthly_interleaved.xlsx")
  if os.path.exists(out_path): os.remove(out_path)

  wb = Workbook()
  del wb[wb.sheetnames[0]]

  interleaved_metrics = add_named_sheet(wb, INTERLEAVED_METRICS)
  first = True
  for mf in metrics_files:
    wbf = load_workbook(mf)
    if INTERLEAVED_METRICS not in wbf.sheetnames: continue
    ws = wbf[INTERLEAVED_METRICS]
    for i, row in enumerate(ws.iter_rows(values_only=True), start=1):
      if i == 1 and not first: continue
      interleaved_metrics.append(row)
    first = False

  if interleaved_metrics.max_row > 1:
    # Style just like regular metrics
    standalone_asr_metrics_baseline.style_columns(interleaved_metrics)

    isum = add_named_sheet(wb, INTERLEAVED_SUMMARY)
    write_interleaved_summary(interleaved_metrics, isum)
    isum.freeze_panes = "A2"
    isum.auto_filter.ref = f"A1:{get_column_letter(isum.max_column)}{isum.max_row}"
    for col, w in {"A": 30, "B": 14, "C": 17, "D": 16, "E": 22, "F": 22}.items():
      isum.column_dimensions[col].width = w
    last = isum.max_row
    fill_con = PatternFill("solid", fgColor="00FFFF")
    for row in isum.iter_rows(min_row=1, max_row=last):
      for c in row:
        c.font = Font(name="Aptos", size=9, bold=(c.row == 1))
        if c.row == last:
          c.fill = fill_con
          c.border = INTERLEAVED_THIN_BORDER

    add_interleaved_sample_summary(wb, interleaved_metrics)

  wb.save(out_path)
  return out_path

def OLD_style_interleaved_metrics_worksheet(ws):
    ws.freeze_panes = "A2"
    ws.auto_filter.ref = f"A1:{get_column_letter(ws.max_column)}{ws.max_row}"

    col_widths = standalone_asr_metrics_baseline.METRICS_COL_WIDTHS
    for col_letter, width in col_widths.items():
        ws.column_dimensions[col_letter].width = width

    for cell in ws[1]:
        cell.font = Font(name="Aptos", size=9)
        cell.alignment = Alignment(horizontal="left", vertical="center")
        cell.fill = PatternFill(
            "solid",
            fgColor=(
                standalone_asr_metrics_baseline.CALL_LEVEL_BKGND_COLOR
                if standalone_asr_metrics_baseline.CALL_LEVEL_GRANULARITY
                else standalone_asr_metrics_baseline.SAMPLE_LEVEL_BKGND_COLOR
            )
        )
        cell.border = standalone_asr_metrics_baseline.THIN_BORDER

def style_interleaved_metrics_worksheet(ws):
  from standalone_asr_metrics_baseline import (
    METRICS_COL_WIDTHS, THIN_BORDER, CALL_LEVEL_GRANULARITY,
    CALL_LEVEL_BKGND_COLOR, SAMPLE_LEVEL_BKGND_COLOR
  )

  ws.auto_filter.ref = f"A1:{get_column_letter(ws.max_column)}{ws.max_row}"
  ws.freeze_panes = "A2"

  fill_color = CALL_LEVEL_BKGND_COLOR if CALL_LEVEL_GRANULARITY else SAMPLE_LEVEL_BKGND_COLOR

  for row in ws.iter_rows(min_row=1, max_row=1):
    for cell in row:
      cell.font = Font(name="Aptos", size=9, bold=True)
      cell.alignment = Alignment("left", "center")
      cell.fill = PatternFill("solid", fgColor=fill_color)
      cell.border = THIN_BORDER

  for col_letter, width in METRICS_COL_WIDTHS.items():
    ws.column_dimensions[col_letter].width = width

def main():
  input_files = standalone_asr_metrics_baseline.list_input_spreadsheets(INTERLEAVED_ROOT_DIR)
  metrics_files = []

  for input_file in input_files:
    input_workbook = load_workbook(input_file)
    worksheet_name = pick_input_worksheet(input_workbook)
    input_worksheet = input_workbook[worksheet_name]
    print(
      f"Using worksheet {worksheet_name} from {input_file} (headers: {standalone_asr_metrics_baseline.get_column_index_map(input_worksheet)})")

    if not has_required_columns(input_worksheet):
      print(f"Skipping {input_file}: missing required headers for input processing")
      continue

    output_path = standalone_asr_metrics_baseline.get_name_of_results_spreadsheet(input_file)
    if os.path.exists(output_path): os.remove(output_path)

    output_workbook = Workbook()
    copy_worksheet = output_workbook.active
    copy_worksheet.title = worksheet_name
    for row in input_worksheet.iter_rows(values_only=True): copy_worksheet.append(row)

    metrics_worksheet = standalone_asr_metrics_baseline.add_metrics_sheet(output_workbook)
    standalone_asr_metrics_baseline.write_header(metrics_worksheet)
    metadata = os.path.basename(input_file).rsplit(".", 1)[0]
    standalone_asr_metrics_baseline.process_sessions(input_worksheet, metrics_worksheet, metadata)
    standalone_asr_metrics_baseline.style_columns(metrics_worksheet)
    summary_worksheet = standalone_asr_metrics_baseline.add_summary_sheet(output_workbook)
    standalone_asr_metrics_baseline.write_summary(metrics_worksheet, summary_worksheet)
    standalone_asr_metrics_baseline.add_sample_summary_sheet(output_workbook, metrics_worksheet)

    if has_vtype_column(input_worksheet):
      #print(f"DEBUG: vtype column found in {inp}, creating interleaved sheets")
      iws = add_named_sheet(output_workbook, INTERLEAVED_METRICS)
      standalone_asr_metrics_baseline.write_header(iws)
      style_interleaved_metrics_worksheet(iws)

      process_interleaved_sessions(input_worksheet, iws, metadata)
      isum = add_named_sheet(output_workbook, INTERLEAVED_SUMMARY)
      write_interleaved_summary(iws, isum)
      add_interleaved_sample_summary(output_workbook, iws)

    output_workbook.save(output_path)
    metrics_files.append(output_path)
    print(f"Saved {output_path}")

  if INTERLEAVED_DO_MONTHLY_CONSOLIDATION and metrics_files:
    monthly_path = create_monthly_interleaved(INTERLEAVED_ROOT_DIR, metrics_files, INTERLEAVED_SPREADSHEET_PREFIX)
    print(f"Saved monthly interleaved metrics to {monthly_path}")

if __name__ == "__main__":
  main()