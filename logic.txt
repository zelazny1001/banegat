# wer_from_vad_analysis.py
# convert java generated analysis files into insightful spreadsheets

from __future__ import annotations
import os
import re
import httpx
from typing import List, Dict
from openpyxl import Workbook, load_workbook
from openpyxl.styles import Font, PatternFill
from openpyxl.utils import get_column_letter
from openpyxl.worksheet.worksheet import Worksheet

# file locations & endpoints
CONSOLIDATED_SPREADSHEET_NAME = "consolidated_analysis.xlsx"
INPUT_ANALYSIS_ROOT_DIR: str = "j:/projects/sheet-logic/"
ANALYSIS_FILE_EXTENSION: str = ".txt"
INPUT_GT_ROOT_DIR: str = "j:/tmp/vad/ground_truth/"
INPUT_FILENAME_PREFIX: str = "customer-side-analysis"
OUTPUT_SPREADSHEET_ROOT_DIR: str = "j:/projects/sheet-logic/analysis-spreadsheets/"
WER_ENDPOINT: str = "http://api_for_wer:2517/wer"

# sheet names
ANALYSIS_WORKSHEET: str = "analysis"
WER_WORKSHEET:    str = "WER"
WER_COMPARISON:   str = "WER_compare"

# column name globals
FIRST_SHEET_HEADERS: List[str] = ["filename", "conditions", "seqNum", "loc", "dur", "start", "end", "transcript"]
WER_SHEET_HEADERS: List[str] = ["filename", "conditions", "full_transcript", "GT", "WER"]

# worksheet 1 (analysis)
FILENAME_WIDTH: int = 35
SEQNUM_WIDTH: int = 7
LOC_WIDTH: int = 7
DUR_WIDTH: int = 6
TRANSCRIPT_WIDTH: int = 60

# worksheet 2 (wer)
CONDITIONS_WIDTH: int = 16
FULL_TRANSCRIPT_WIDTH: int = 30
GT_WIDTH: int = 30
WER_WIDTH: int = 8


def convert_and_format_column(
    ws: Worksheet,
    col_idx: int,
    start_row: int = 2,
    fmt: str = "0.00"
) -> None:
    for r in range(start_row, ws.max_row + 1):
        cell = ws.cell(row=r, column=col_idx)
        v = cell.value
        if isinstance(v, str):
            try:
                cell.value = float(v)
            except ValueError:
                continue
        if isinstance(cell.value, (int, float)):
            cell.number_format = fmt


def convert_and_format_column_by_header(
    ws: Worksheet,
    header: str,
    start_row: int = 2,
    fmt: str = "0.00"
) -> None:
    """
    Find the column whose heading in row 1 equals `header`, then
    convert & format that column.
    """
    for idx, cell in enumerate(ws[1], start=1):
        if cell.value == header:
            convert_and_format_column(ws, idx, start_row, fmt)
            return
    raise ValueError(f"Header {header!r} not found in sheet {ws.title}")


def get_analysis_files(root_dir: str, extension: str) -> List[str]:
    return [
        os.path.join(root_dir, f)
        for f in os.listdir(root_dir)
        if f.endswith(extension)
    ]

def get_suffix_from_filename(file_path: str, input_filename_prefix: str) -> str:
    input_filename = os.path.splitext(os.path.basename(file_path))[0]
    if not input_filename.startswith(input_filename_prefix):
        return input_filename
    prefix_len = len(input_filename_prefix)
    dash_found_at = input_filename.find("-", prefix_len)
    if dash_found_at == -1:
        return input_filename
    return input_filename[dash_found_at + 1:]

def remove_braces(text: str) -> str:
    return text.replace("{", "").replace("}", "")

def preprocess(text):
    if not text:
        return ""
    text = str(text).lower()
    text = re.sub(r'\{[^}]*\}|<[^>]*>', ' ', text)
    text = re.sub(r'[{}<>.,\-?…]', ' ', text)
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

def get_column_indices(header_cols: List[str], *names: str) -> Dict[str, int]:
    indices: Dict[str, int] = {}
    for name in names:
        if name not in header_cols:
            raise ValueError(f"Column {name!r} not found in header row")
        indices[name] = header_cols.index(name)
    return indices

def parse_analysis_file(file_path: str) -> List[Dict[str, str]]:
    records: List[Dict[str, str]] = []
    with open(file_path, encoding="utf-8") as f:
        # read header and build name→index map
        header_line = next(f)
        headers = [c.strip() for c in header_line.rstrip("\n").split("|")]
        idx = get_column_indices(
            headers,
            "filename",
            "seqNum",
            "loc",
            "dur",
            "start",
            "end",
            "transcript"
        )

        for line in f:
            cols = [c.strip() for c in line.rstrip("\n").split("|")]
            records.append({
                "filename":   cols[idx["filename"]],
                "seqNum":     cols[idx["seqNum"]],
                "loc":        cols[idx["loc"]],
                "dur":        cols[idx["dur"]],
                "start":      cols[idx["start"]],
                "end":        cols[idx["end"]],
                "transcript": cols[idx["transcript"]],
            })
    return records

def group_transcripts_by_filename(records: List[Dict[str, str]]) -> Dict[str, List[str]]:
    groups: Dict[str, List[str]] = {}
    for r in records:
        groups.setdefault(r["filename"], []).append(r["transcript"])
    return groups

def find_ground_truth(filename: str, gt_root_dir: str) -> str:
    candidates = sorted(
        (fn for fn in os.listdir(gt_root_dir)
         if fn.startswith("ground_truth_") and fn.endswith(".txt")),
        key=lambda fn: len(fn[len("ground_truth_"):-4]),
        reverse=True
    )
    for fn in candidates:
        suffix = fn[len("ground_truth_"):-4]
        if suffix in filename:
            path = os.path.join(gt_root_dir, fn)
            with open(path, encoding="utf-8") as gf:
                raw = gf.read().replace('\n', ' ')
                return preprocess(raw)
    print("no ground truth available")
    return "no ground truth available"

def calculate_wer(ground_truth: str, transcript: str, wer_endpoint: str) -> str:
    resp = httpx.post(wer_endpoint,
                      json={"groundTruth": ground_truth, "transcript": transcript},
                      timeout=5.0)
    text = resp.text.strip()
    try:
        value = float(text)
        return f"{value:.2f}"
    except ValueError:
        return "WER API Error"

def write_analysis_sheet(wb: Workbook, conditions: str, records: List[Dict[str, str]]) -> None:
    ws = wb.active
    ws.title = ANALYSIS_WORKSHEET
    ws.append(FIRST_SHEET_HEADERS)
    for r in records:
        ws.append([
            r["filename"],
            conditions,
            r["seqNum"],
            r["loc"],
            r["dur"],
            r["start"],
            r["end"],
            r["transcript"]
        ])
    header_font = Font(name="Aptos", size=9, bold=True)
    data_font = Font(name="Aptos", size=9)
    for cell in ws[1]:
        cell.font = header_font
    for row in ws.iter_rows(min_row=2, max_col=len(FIRST_SHEET_HEADERS)):
        for cell in row:
            cell.font = data_font
    ws.freeze_panes = "A2"
    ws.auto_filter.ref = f"A1:{get_column_letter(len(FIRST_SHEET_HEADERS))}{len(records) + 1}"
    for idx, w in enumerate([FILENAME_WIDTH, CONDITIONS_WIDTH, SEQNUM_WIDTH, LOC_WIDTH, DUR_WIDTH, TRANSCRIPT_WIDTH], start=1):
        ws.column_dimensions[get_column_letter(idx)].width = w

def write_wer_sheet(
    wb: Workbook,
    conditions: str,
    records: List[Dict[str, str]],
    gt_root_dir: str,
    wer_endpoint: str,
) -> None:
    ws = wb.create_sheet(WER_WORKSHEET)
    ws.append(WER_SHEET_HEADERS)
    groups = group_transcripts_by_filename(records)
    header_font = Font(name="Aptos", size=9, bold=True)
    data_font   = Font(name="Aptos", size=9)

    for filename, transcripts in groups.items():
        full    = " ".join(transcripts)
        gt      = find_ground_truth(filename, gt_root_dir)

        full = preprocess(full) # for second pass, after changing "braced_transcript" to "transcript"
        wer_str = calculate_wer(gt, full, wer_endpoint)
        # store as float when possible
        try:
            wer_val = float(wer_str)
        except ValueError:
            wer_val = wer_str
        ws.append([filename, conditions, full, gt, wer_val])

    # style header and data
    for cell in ws[1]:
        cell.font = header_font
    for row in ws.iter_rows(min_row=2, max_col=len(WER_SHEET_HEADERS)):
        for cell in row:
            cell.font = data_font

    ws.freeze_panes = "A2"
    ws.auto_filter.ref = f"A1:{get_column_letter(len(WER_SHEET_HEADERS))}{ws.max_row}"

    # set column widths
    for idx, width in enumerate(
        [FILENAME_WIDTH, CONDITIONS_WIDTH, FULL_TRANSCRIPT_WIDTH, GT_WIDTH, WER_WIDTH],
        start=1
    ):
        ws.column_dimensions[get_column_letter(idx)].width = width

    # convert & format the WER column by header
    convert_and_format_column_by_header(ws, "WER")


def process_file(file_path: str,
                 input_filename_prefix: str,
                 gt_root_dir: str,
                 wer_endpoint: str,
                 output_root_dir: str) -> None:
    records = parse_analysis_file(file_path)
    suffix = get_suffix_from_filename(file_path, input_filename_prefix)
    stem = os.path.splitext(os.path.basename(file_path))[0]
    output_path = os.path.join(output_root_dir, f"{stem}.xlsx")
    wb = Workbook()
    write_analysis_sheet(wb, suffix, records)
    write_wer_sheet(wb, suffix, records, gt_root_dir, wer_endpoint)
    wb.save(output_path)

def create_consolidated_spreadsheet(
    output_root_dir: str,
    analysis_worksheet: str,
    first_sheet_headers: List[str],
    wer_worksheet: str,
    wer_sheet_headers: List[str],
) -> None:

    consolidated_path = os.path.join(output_root_dir, CONSOLIDATED_SPREADSHEET_NAME)
    wb_out = Workbook()
    ws_a = wb_out.active
    ws_a.title = analysis_worksheet
    ws_a.append(first_sheet_headers)
    ws_w = wb_out.create_sheet(wer_worksheet)
    ws_w.append(wer_sheet_headers)

    for fname in os.listdir(output_root_dir):
        if not fname.endswith(".xlsx") or fname == os.path.basename(CONSOLIDATED_SPREADSHEET_NAME):
            continue
        path = os.path.join(output_root_dir, fname)
        wb_in = load_workbook(path, data_only=True)
        if analysis_worksheet in wb_in.sheetnames:
            for row in wb_in[analysis_worksheet].iter_rows(min_row=2, values_only=True):
                ws_a.append(row)
        if wer_worksheet in wb_in.sheetnames:
            for row in wb_in[wer_worksheet].iter_rows(min_row=2, values_only=True):
                ws_w.append(row)

    hf = Font(name="Aptos", size=9, bold=True)
    df = Font(name="Aptos", size=9)

    # style analysis sheet
    for cell in ws_a[1]:
        cell.font = hf
    for row in ws_a.iter_rows(min_row=2, max_col=len(first_sheet_headers)):
        for cell in row:
            cell.font = df
    ws_a.freeze_panes = "A2"
    ws_a.auto_filter.ref = f"A1:{get_column_letter(len(first_sheet_headers))}{ws_a.max_row}"
    for idx, w in enumerate(
        [FILENAME_WIDTH, CONDITIONS_WIDTH, SEQNUM_WIDTH, LOC_WIDTH, DUR_WIDTH, DUR_WIDTH, DUR_WIDTH, TRANSCRIPT_WIDTH],
        start=1
    ):
        ws_a.column_dimensions[get_column_letter(idx)].width = w

    # style WER sheet
    for cell in ws_w[1]:
        cell.font = hf
    for row in ws_w.iter_rows(min_row=2, max_col=len(wer_sheet_headers)):
        for cell in row:
            cell.font = df
    ws_w.freeze_panes = "A2"
    ws_w.auto_filter.ref = f"A1:{get_column_letter(len(wer_sheet_headers))}{ws_w.max_row}"
    for idx, w in enumerate(
        [FILENAME_WIDTH, CONDITIONS_WIDTH, FULL_TRANSCRIPT_WIDTH, GT_WIDTH, WER_WIDTH],
        start=1
    ):
        ws_w.column_dimensions[get_column_letter(idx)].width = w

    wb_out.save(consolidated_path)

def create_wer_comparison(
    wb: Workbook,
    wer_sheet_name: str,
    comparison_sheet_name: str,
) -> None:
    ws_w = wb[wer_sheet_name]
    mapping: Dict[str, Dict[str, str]] = {}
    conditions: List[str] = []

    # build mapping filename → {condition: wer}
    for fn, cond, *_, wer in ws_w.iter_rows(min_row=2, values_only=True):
        mapping.setdefault(fn, {})[cond] = wer
        if cond not in conditions:
            conditions.append(cond)

    # new sheet with one column per condition
    ws_c = wb.create_sheet(comparison_sheet_name)
    header = ["filename"] + conditions
    ws_c.append(header)

    # populate rows
    for fn, cm in mapping.items():
        row = [fn] + [cm.get(cond, "") for cond in conditions]
        ws_c.append(row)

    # styling
    hf = Font(name="Aptos", size=9, bold=True)
    df = Font(name="Aptos", size=9)
    ncols = 1 + len(conditions)

    for cell in ws_c[1]:
        cell.font = hf
    for r in ws_c.iter_rows(min_row=2, max_col=ncols):
        for cell in r:
            cell.font = df

    ws_c.freeze_panes = "A2"
    ws_c.auto_filter.ref = f"A1:{get_column_letter(ncols)}{ws_c.max_row}"

    # set widths
    ws_c.column_dimensions[get_column_letter(1)].width = FILENAME_WIDTH
    for i in range(len(conditions)):
        ws_c.column_dimensions[get_column_letter(2 + i)].width = CONDITIONS_WIDTH

    # convert & format each condition column by header
    for cond in conditions:
        convert_and_format_column_by_header(ws_c, cond)

def highlight_lowest_wer(
    consolidated_path: str,
    comparison_sheet_name: str,
) -> None:

    wb = load_workbook(consolidated_path)
    ws = wb[comparison_sheet_name]
    cyan_fill = PatternFill(fill_type="solid", fgColor="FF00FFFF")

    for row in ws.iter_rows(min_row=2):
        best_cell = None
        best_val = None
        # examine columns 2…end
        for cell in row[1:]:
            v = cell.value
            if v is None:
                continue
            try:
                f = float(v)
            except (ValueError, TypeError):
                continue
            if best_val is None or f < best_val:
                best_val = f
                best_cell = cell

        if best_cell is not None:
            best_cell.fill = cyan_fill

    wb.save(consolidated_path)

def append_average_wer_row(
    consolidated_path: str,
    comparison_sheet_name: str,
) -> None:
    from openpyxl import load_workbook
    from openpyxl.styles import Font, PatternFill

    wb = load_workbook(consolidated_path)
    ws = wb[comparison_sheet_name]

    max_row = ws.max_row
    max_col = ws.max_column

    # compute per‐column averages (cols 2…max_col)
    averages: list[float] = []
    for col in range(2, max_col + 1):
        vals: list[float] = []
        for row in range(2, max_row + 1):
            v = ws.cell(row=row, column=col).value
            try:
                vals.append(float(v))
            except (TypeError, ValueError):
                continue
        avg = sum(vals) / len(vals) if vals else 0.0
        averages.append(avg)

    # append the AVERAGE WER row
    avg_row = max_row + 1
    cell0 = ws.cell(row=avg_row, column=1)
    cell0.value = "AVERAGE WER"
    cell0.font = Font(bold=True)
    for i, avg in enumerate(averages, start=2):
        c = ws.cell(row=avg_row, column=i)
        c.value = round(avg, 2)
        c.number_format = "0.00"

    # highlight lowest average in cyan
    min_val = min(averages)
    min_col = averages.index(min_val) + 2
    cyan = PatternFill(fill_type="solid", fgColor="FF00FFFF")
    ws.cell(row=avg_row, column=min_col).fill = cyan

    wb.save(consolidated_path)

def main(
    analysis_root_dir: str,
    extension: str,
    input_filename_prefix: str,
    gt_root_dir: str,
    wer_endpoint: str,
    output_root_dir: str,
) -> None:
    for file_path in get_analysis_files(analysis_root_dir, extension):
        process_file(
            file_path,
            input_filename_prefix,
            gt_root_dir,
            wer_endpoint,
            output_root_dir,
        )

    create_consolidated_spreadsheet(
        output_root_dir,
        ANALYSIS_WORKSHEET,
        FIRST_SHEET_HEADERS,
        WER_WORKSHEET,
        WER_SHEET_HEADERS,
    )
    consolidated_path = analysis_root_dir + CONSOLIDATED_SPREADSHEET_NAME
    wb = load_workbook(consolidated_path)
    create_wer_comparison(
        wb,
        WER_WORKSHEET,
        WER_COMPARISON,
    )

    highlight_lowest_wer(
        consolidated_path,
        WER_COMPARISON,
    )

    append_average_wer_row(
        os.path.join(output_root_dir, CONSOLIDATED_SPREADSHEET_NAME),
        WER_COMPARISON,
    )

if __name__ == "__main__":
    main(INPUT_ANALYSIS_ROOT_DIR,
         ANALYSIS_FILE_EXTENSION,
         INPUT_FILENAME_PREFIX,
         INPUT_GT_ROOT_DIR,
         WER_ENDPOINT,
         OUTPUT_SPREADSHEET_ROOT_DIR)
		 
=============================

# interleave_agent_and_customer_calls.py

import re
from collections import defaultdict
from openpyxl import load_workbook
from openpyxl.styles import Font
from openpyxl.utils import get_column_letter

SPREADSHEET_LOCATION = "PATH_TO_DIRECTORY/"
SPREADSHEET_NAME = "YOUR_SPREADSHEET.xlsx"
SPREADSHEET_PATH = SPREADSHEET_LOCATION + SPREADSHEET_NAME
ANALYSIS_WORKSHEET = "analysis"

AGENT_SUFFIX_PATTERN = r"_Agent_(\d+)_(\d+)"
CUSTOMER_SUFFIX_PATTERN = r"_Cust_(\d+)_(\d+)"

FILENAME_COLUMN = "filename"
START_COLUMN = "start"
TRANSCRIPT_COLUMN = "transcript"
CALL_COLUMN = "call"
SPEAKER_COLUMN = "speaker"
CALL_TRANSCRIPT_COLUMN = "call_transcript"

CALL_COLUMN_WIDTH = 12
SPEAKER_COLUMN_WIDTH = 12

def get_call_id(filename: str) -> str:
    m = re.search(AGENT_SUFFIX_PATTERN, filename)
    if m:
        return f"call_{m.group(1)}_{m.group(2)}"
    m = re.search(CUSTOMER_SUFFIX_PATTERN, filename)
    if m:
        return f"call_{m.group(1)}_{m.group(2)}"
    return ""

def get_speaker(filename: str) -> str:
    if "_Agent_" in filename:
        return "Agent"
    if "_Cust_" in filename:
        return "Customer"
    return ""

def load_sheet(path: str, sheet_name: str):
    wb = load_workbook(path)
    return wb, wb[sheet_name]

def map_headers(ws):
    return {cell.value: idx + 1 for idx, cell in enumerate(ws[1])}

def add_headers(ws, start_idx: int):
    ws.cell(row=1, column=start_idx, value=CALL_COLUMN)
    ws.cell(row=1, column=start_idx + 1, value=SPEAKER_COLUMN)
    ws.cell(row=1, column=start_idx + 2, value=CALL_TRANSCRIPT_COLUMN)
    return start_idx, start_idx + 1, start_idx + 2

def read_records(ws, idx_map):
    records = []
    for r in range(2, ws.max_row + 1):
        filename = ws.cell(row=r, column=idx_map[FILENAME_COLUMN]).value
        start = ws.cell(row=r, column=idx_map[START_COLUMN]).value
        transcript = ws.cell(row=r, column=idx_map[TRANSCRIPT_COLUMN]).value
        call_id = get_call_id(filename)
        if not call_id:
            print(f"Filename '{filename}' missing suffix; aborting.")
            return []
        records.append({
            "row": r,
            "call": call_id,
            "speaker": get_speaker(filename),
            "start": int(start),
            "transcript": transcript
        })
    return records

def build_call_transcripts(records):
    grouped = defaultdict(list)
    for rec in records:
        key = (rec["start"], 0 if rec["speaker"] == "Agent" else 1)
        grouped[rec["call"]].append((key, rec["transcript"]))
    return {
        call: "\n".join(t for _, t in sorted(items, key=lambda x: x[0]))
        for call, items in grouped.items()
    }

def write_new_columns(ws, records, transcript_map, col_call, col_speaker, col_ct):
    for rec in records:
        r = rec["row"]
        ws.cell(row=r, column=col_call, value=rec["call"])
        ws.cell(row=r, column=col_speaker, value=rec["speaker"])
        ws.cell(row=r, column=col_ct, value=transcript_map.get(rec["call"], ""))

def apply_styling(ws, idx_map, col_call, col_speaker, col_ct):
    header_font = Font(name="Aptos", size=9, bold=True)
    data_font = Font(name="Aptos", size=9)
    tr_width = ws.column_dimensions[get_column_letter(idx_map[TRANSCRIPT_COLUMN])].width
    ws.column_dimensions[get_column_letter(col_call)].width = CALL_COLUMN_WIDTH
    ws.column_dimensions[get_column_letter(col_speaker)].width = SPEAKER_COLUMN_WIDTH
    ws.column_dimensions[get_column_letter(col_ct)].width = tr_width
    for col in [col_call, col_speaker, col_ct]:
        ws.cell(row=1, column=col).font = header_font
        for r in range(2, ws.max_row + 1):
            ws.cell(row=r, column=col).font = data_font
    last_col = max(idx_map[TRANSCRIPT_COLUMN], col_ct)
    ws.freeze_panes = "A2"
    ws.auto_filter.ref = f"A1:{get_column_letter(last_col)}{ws.max_row}"

def interleave_calls():
    wb, ws = load_sheet(SPREADSHEET_PATH, ANALYSIS_WORKSHEET)
    idx_map = map_headers(ws)
    records = read_records(ws, idx_map)
    if not records:
        return
    start_idx = len(idx_map) + 1
    col_call, col_speaker, col_ct = add_headers(ws, start_idx)
    tm = build_call_transcripts(records)
    write_new_columns(ws, records, tm, col_call, col_speaker, col_ct)
    apply_styling(ws, idx_map, col_call, col_speaker, col_ct)
    wb.save(SPREADSHEET_PATH)

def main():
    interleave_calls()

if __name__ == "__main__":
    main()


=============================

package analyzer;

import java.io.ByteArrayInputStream;
import java.io.File;
import java.io.IOException;
import java.nio.file.Files;
import java.nio.file.Paths;
import javax.sound.sampled.AudioFileFormat;
import javax.sound.sampled.AudioFormat;
import javax.sound.sampled.AudioInputStream;
import javax.sound.sampled.AudioSystem;

public class G711ToWavConverter {

    public static byte[] readInputFile(String inputFilePath) throws IOException {
        return Files.readAllBytes(Paths.get(inputFilePath));
    }

    public static AudioInputStream convertToWavStream(byte[] data, int start, int stop) {
        int startIndex = start - 1;
        int endIndex = stop - 1;

        if (startIndex < 0 || endIndex >= data.length || startIndex > endIndex) {
            throw new IllegalArgumentException("Invalid start/stop indexes");
        }

        byte[] segment = new byte[endIndex - startIndex + 1];
        System.arraycopy(data, startIndex, segment, 0, segment.length);

        return createAudioInputStream(segment);
    }

    public static AudioInputStream convertToWavStream(byte[] data) {
        return createAudioInputStream(data);
    }

    private static AudioInputStream createAudioInputStream(byte[] ulawData) {
        AudioFormat format = new AudioFormat(
                AudioFormat.Encoding.ULAW,
                8000.0f,
                8,
                1,
                1,
                8000.0f,
                false
        );
        ByteArrayInputStream bais = new ByteArrayInputStream(ulawData);
        return new AudioInputStream(bais, format, ulawData.length);
    }

    public static void writeWavToFile(AudioInputStream stream, String outputFilePath) throws IOException {
        AudioSystem.write(stream, AudioFileFormat.Type.WAVE, new File(outputFilePath));
        stream.close();
        System.out.println("Successfully created WAV file: " + outputFilePath);
    }

    public static void main(String[] args) {
        try {
            String inputFilePath = "input.g711";
            String outputFilePath = "output.wav";

            byte[] fullData = readInputFile(inputFilePath);
            AudioInputStream wavStream = convertToWavStream(fullData, 100, 5000);
            writeWavToFile(wavStream, outputFilePath);
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}